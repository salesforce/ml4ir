{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ml4ir](https://github.com/salesforce/ml4ir) \n",
    "#### open source, modular, python3, tensorflow2.0 library for IR based ML applications\n",
    "--------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/ml4ir.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's load the data and take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Logger is initialized...\n",
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv, ..\n",
      "INFO:root:(5676, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>rank</th>\n",
       "      <th>text_match_score</th>\n",
       "      <th>page_views_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>name_match</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>query_0</td>\n",
       "      <td>UQHA3QP4ZVO</td>\n",
       "      <td>1</td>\n",
       "      <td>1.101297</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>query_0</td>\n",
       "      <td>UQHA3QP4ZVO</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380570</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>1</td>\n",
       "      <td>1.024334</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>2</td>\n",
       "      <td>0.821515</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>3</td>\n",
       "      <td>0.821323</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>4</td>\n",
       "      <td>0.821515</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>5</td>\n",
       "      <td>0.821323</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id   query_text  rank  text_match_score  page_views_score  \\\n",
       "4365  query_0  UQHA3QP4ZVO     1          1.101297          0.002044   \n",
       "4366  query_0  UQHA3QP4ZVO     2          0.380570          0.004078   \n",
       "4371  query_1  8M3NWYX4E6I     1          1.024334          0.008686   \n",
       "4368  query_1  8M3NWYX4E6I     2          0.821515          0.200264   \n",
       "4370  query_1  8M3NWYX4E6I     3          0.821323          0.200264   \n",
       "4369  query_1  8M3NWYX4E6I     4          0.821515          0.200264   \n",
       "4367  query_1  8M3NWYX4E6I     5          0.821323          0.200264   \n",
       "\n",
       "      quality_score  domain_id domain_name  name_match  clicked  \n",
       "4365        0.00000          0    domain_0           0        1  \n",
       "4366        0.30103          0    domain_0           0        0  \n",
       "4371        0.30103          1    domain_1           1        1  \n",
       "4368        0.00000          1    domain_1           1        0  \n",
       "4370        0.00000          1    domain_1           0        0  \n",
       "4369        0.00000          1    domain_1           0        0  \n",
       "4367        0.00000          1    domain_1           1        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4ir.base.io import file_io\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"Logger is initialized...\")\n",
    "\n",
    "\n",
    "# Load data\n",
    "CSV_DATA_DIR = '../ml4ir/applications/ranking/tests/data/csv'\n",
    "\n",
    "df = file_io.read_df_list(glob.glob(os.path.join(CSV_DATA_DIR, \"train\", \"*.csv\")), log=logger)\n",
    "\n",
    "logger.info(df.shape)\n",
    "\n",
    "df[[c for c in df.columns if c != \"clicked\"] + [\"clicked\"]].sort_values([\"query_id\", \"rank\"]).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define the feature configuration for our data\n",
    "\n",
    "### ... brace yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading feature config from YAML string\n",
      "INFO:root:Feature config loaded successfully\n",
      "INFO:root:Trainable Features : \n",
      "text_match_score\n",
      "page_views_score\n",
      "quality_score\n",
      "query_text\n",
      "domain_id\n",
      "domain_name\n",
      "INFO:root:Label : clicked\n",
      "INFO:root:Metadata Features : \n",
      "query_id\n",
      "clicked\n",
      "rank\n",
      "name_match\n",
      "INFO:root:[\n",
      "    {\n",
      "        \"name\": \"query_id\",\n",
      "        \"node_name\": \"query_id\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"string\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"queryId\",\n",
      "            \"required\": false,\n",
      "            \"default_value\": \"\"\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"clicked\",\n",
      "        \"node_name\": \"clicked\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"clicked\",\n",
      "            \"required\": false,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"rank\",\n",
      "        \"node_name\": \"rank\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"originalRank\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"text_match_score\",\n",
      "        \"node_name\": \"text_match_score\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"float\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"textMatchScore\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0.0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"page_views_score\",\n",
      "        \"node_name\": \"page_views_score\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"float\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"pageViewsScore\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0.0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"quality_score\",\n",
      "        \"node_name\": \"quality_score\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"float\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"preprocessing_info\": [\n",
      "            {\n",
      "                \"fn\": \"signed_log\",\n",
      "                \"args\": {\n",
      "                    \"shift\": 1\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"qualityScore\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0.0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"name_match\",\n",
      "        \"node_name\": \"name_match\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"float\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"is_secondary_label\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"nameMatch\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0.0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"query_text\",\n",
      "        \"node_name\": \"query_text\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"string\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null,\n",
      "            \"fn\": \"bytes_sequence_to_encoding_bilstm\",\n",
      "            \"args\": {\n",
      "                \"encoding_type\": \"bilstm\",\n",
      "                \"encoding_size\": 128,\n",
      "                \"embedding_size\": 128,\n",
      "                \"max_length\": 20\n",
      "            }\n",
      "        },\n",
      "        \"preprocessing_info\": [\n",
      "            {\n",
      "                \"fn\": \"preprocess_text\",\n",
      "                \"args\": {\n",
      "                    \"remove_punctuation\": true,\n",
      "                    \"to_lower\": true\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"q\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": \"\"\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"domain_id\",\n",
      "        \"node_name\": \"domain_id\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"is_group_metric_key\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null,\n",
      "            \"fn\": \"custom_categorical_embedding\",\n",
      "            \"args\": {\n",
      "                \"num_buckets\": 8,\n",
      "                \"embedding_size\": 64,\n",
      "                \"default_value\": null\n",
      "            }\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"domainID\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"domain_name\",\n",
      "        \"node_name\": \"domain_name\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"string\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"is_group_metric_key\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null,\n",
      "            \"fn\": \"categorical_embedding_with_vocabulary_file\",\n",
      "            \"args\": {\n",
      "                \"vocabulary_file\": \"../ml4ir/applications/ranking/tests/data/config/group_name_vocab_no_id.csv\",\n",
      "                \"embedding_size\": 64,\n",
      "                \"default_value\": -1,\n",
      "                \"num_oov_buckets\": 1\n",
      "            }\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"domainName\",\n",
      "            \"required\": true,\n",
      "            \"default_value\": \"\"\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Set up the feature configurations\n",
    "from ml4ir.base.features.feature_config import parse_config\n",
    "from ml4ir.base.features.feature_config import ExampleFeatureConfig\n",
    "from ml4ir.base.config.keys import TFRecordTypeKey\n",
    "import json\n",
    "\n",
    "feature_config_yaml = '''\n",
    "query_key: \n",
    "  name: query_id\n",
    "  node_name: query_id\n",
    "  trainable: false\n",
    "  dtype: string\n",
    "  log_at_inference: true\n",
    "  feature_layer_info:\n",
    "    type: numeric\n",
    "    shape: null\n",
    "  serving_info:\n",
    "    name: queryId\n",
    "    required: false\n",
    "    default_value: \"\"\n",
    "  tfrecord_type: context\n",
    "label:\n",
    "  name: clicked\n",
    "  node_name: clicked\n",
    "  trainable: false\n",
    "  dtype: int64\n",
    "  log_at_inference: true\n",
    "  feature_layer_info:\n",
    "    type: numeric\n",
    "    shape: null\n",
    "  serving_info:\n",
    "    name: clicked\n",
    "    required: false\n",
    "    default_value: 0\n",
    "  tfrecord_type: sequence\n",
    "features:\n",
    "  - name: rank\n",
    "    node_name: rank\n",
    "    trainable: false\n",
    "    dtype: int64\n",
    "    log_at_inference: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: originalRank\n",
    "      required: true\n",
    "      default_value: 0\n",
    "    tfrecord_type: sequence\n",
    "  - name: text_match_score\n",
    "    node_name: text_match_score\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: textMatchScore\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: page_views_score\n",
    "    node_name: page_views_score\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: pageViewsScore\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: quality_score\n",
    "    node_name: quality_score\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    preprocessing_info:\n",
    "      - fn: signed_log\n",
    "        args:\n",
    "          shift: 1\n",
    "    serving_info:\n",
    "      name: qualityScore\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: name_match\n",
    "    node_name: name_match\n",
    "    trainable: false\n",
    "    dtype: float\n",
    "    log_at_inference: true\n",
    "    is_secondary_label: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: nameMatch\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: query_text\n",
    "    node_name: query_text\n",
    "    trainable: true\n",
    "    dtype: string\n",
    "    log_at_inference: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      fn: bytes_sequence_to_encoding_bilstm\n",
    "      args:\n",
    "        encoding_type: bilstm\n",
    "        encoding_size: 128\n",
    "        embedding_size: 128\n",
    "        max_length: 20\n",
    "    preprocessing_info:\n",
    "      - fn: preprocess_text\n",
    "        args:\n",
    "          remove_punctuation: true\n",
    "          to_lower: true\n",
    "    serving_info:\n",
    "      name: q\n",
    "      required: true\n",
    "      default_value: \"\"\n",
    "    tfrecord_type: context\n",
    "  - name: domain_id\n",
    "    node_name: domain_id\n",
    "    trainable: true\n",
    "    dtype: int64\n",
    "    log_at_inference: false\n",
    "    is_group_metric_key: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      fn: custom_categorical_embedding\n",
    "      args:\n",
    "        num_buckets: 8\n",
    "        embedding_size: 64\n",
    "        default_value: null\n",
    "    serving_info:\n",
    "      name: domainID\n",
    "      required: true\n",
    "      default_value: 0\n",
    "    tfrecord_type: context\n",
    "  - name: domain_name\n",
    "    node_name: domain_name\n",
    "    trainable: true\n",
    "    dtype: string\n",
    "    log_at_inference: true\n",
    "    is_group_metric_key: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      # fn: categorical_embedding_with_hash_buckets\n",
    "      # args:\n",
    "      #   num_hash_buckets: 4\n",
    "      #   hash_bucket_size: 64\n",
    "      #   embedding_size: 32\n",
    "      #   merge_mode: concat\n",
    "      fn: categorical_embedding_with_vocabulary_file\n",
    "      args:\n",
    "        vocabulary_file: '../ml4ir/applications/ranking/tests/data/config/group_name_vocab_no_id.csv'\n",
    "        embedding_size: 64\n",
    "        default_value: -1\n",
    "        num_oov_buckets: 1\n",
    "    serving_info:\n",
    "      name: domainName\n",
    "      required: true\n",
    "      default_value: \"\"\n",
    "    tfrecord_type: context\n",
    "'''\n",
    "feature_config: ExampleFeatureConfig = parse_config(TFRecordTypeKey.EXAMPLE, feature_config_yaml, logger=logger)\n",
    "    \n",
    "logging.info(json.dumps(feature_config.get_all_features(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords - Examples vs SequenceExamples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/tfrecords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to load the data and save awesome TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>rank</th>\n",
       "      <th>text_match_score</th>\n",
       "      <th>page_views_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>clicked</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>name_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query_2</td>\n",
       "      <td>MHS7A7RJB1Y4BJT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>domain_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query_2</td>\n",
       "      <td>MHS7A7RJB1Y4BJT</td>\n",
       "      <td>1</td>\n",
       "      <td>1.063190</td>\n",
       "      <td>0.205381</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>domain_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query_5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>6</td>\n",
       "      <td>1.368108</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query_5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>3</td>\n",
       "      <td>1.370628</td>\n",
       "      <td>0.041261</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query_5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>4</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>0.082535</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id       query_text  rank  text_match_score  page_views_score  \\\n",
       "0  query_2  MHS7A7RJB1Y4BJT     2          0.473730          0.000000   \n",
       "1  query_2  MHS7A7RJB1Y4BJT     1          1.063190          0.205381   \n",
       "2  query_5           KNJNWV     6          1.368108          0.030636   \n",
       "3  query_5           KNJNWV     3          1.370628          0.041261   \n",
       "4  query_5           KNJNWV     4          1.366700          0.082535   \n",
       "\n",
       "   quality_score  clicked  domain_id domain_name  name_match  \n",
       "0        0.00000        0          2    domain_2           1  \n",
       "1        0.30103        1          2    domain_2           1  \n",
       "2        0.00000        0          0    domain_0           0  \n",
       "3        0.30103        0          0    domain_0           0  \n",
       "4        0.30103        0          0    domain_0           0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4ir.base.io import file_io\n",
    "from ml4ir.base.data import tfrecord_writer\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "df = file_io.read_df_list(glob.glob(os.path.join(CSV_DATA_DIR, \"train\", \"*.csv\")))\n",
    "\n",
    "# Save as TFRecord SequenceExample/Example\n",
    "TFRECORD_DIR = '../data/pointwise_ranking_demo/'\n",
    "if not os.path.exists(TFRECORD_DIR):\n",
    "    os.makedirs('../data/pointwise_ranking_demo/')\n",
    "tfrecord_writer.write_from_df(df,\n",
    "                              tfrecord_file=os.path.join(TFRECORD_DIR, 'file_0.tfrecord'),\n",
    "                              feature_config=feature_config,\n",
    "                              tfrecord_type=TFRecordTypeKey.EXAMPLE)\n",
    "\n",
    "# Let's see what it looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TFRecords and add custom preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n",
      "({'domain_id': [[2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]],\n",
      "  'domain_name': [[\"domain_2\"]\n",
      " [\"domain_2\"]\n",
      " [\"domain_0\"]\n",
      " [\"domain_0\"]\n",
      " [\"domain_0\"]],\n",
      "  'name_match': [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]],\n",
      "  'page_views_score': [[0]\n",
      " [0.205380633]\n",
      " [0.0306360275]\n",
      " [0.0412614979]\n",
      " [0.0825348869]],\n",
      "  'quality_score': [[0]\n",
      " [0.263156295]\n",
      " [0]\n",
      " [0.263156295]\n",
      " [0.263156295]],\n",
      "  'query_id': [[\"query_2\"]\n",
      " [\"query_2\"]\n",
      " [\"query_5\"]\n",
      " [\"query_5\"]\n",
      " [\"query_5\"]],\n",
      "  'query_text': [[\"mhs7a7rjb1y4bjt\"]\n",
      " [\"mhs7a7rjb1y4bjt\"]\n",
      " [\"knjnwv\"]\n",
      " [\"knjnwv\"]\n",
      " [\"knjnwv\"]],\n",
      "  'rank': [[2]\n",
      " [1]\n",
      " [6]\n",
      " [3]\n",
      " [4]],\n",
      "  'text_match_score': [[0.473729521]\n",
      " [1.06319]\n",
      " [1.36810815]\n",
      " [1.37062836]\n",
      " [1.36669993]]},\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]])\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.data import tfrecord_reader\n",
    "from tensorflow import print as tfprint\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def strip_numbers(feature_tensor):\n",
    "    return tf.strings.regex_replace(feature_tensor, \"[0-9]\", \"\")\n",
    "\n",
    "@tf.function\n",
    "def signed_log(feature_tensor, shift=1.):\n",
    "    \"\"\"Signed log\"\"\"\n",
    "    return tf.math.log(\n",
    "                    tf.add(feature_tensor,\n",
    "                    tf.cast(tf.constant(shift),\n",
    "                            tf.float32)\n",
    "                          )\n",
    "                )\n",
    "\n",
    "\n",
    "# Define per instance preprocessing functions\n",
    "preprocessing_fns = {\n",
    "    \"strip_numbers\": strip_numbers,\n",
    "    \"signed_log\": signed_log\n",
    "}\n",
    "\n",
    "# Create a TFRecord dataset\n",
    "dataset = tfrecord_reader.read(data_dir=TFRECORD_DIR,\n",
    "                               feature_config=feature_config,\n",
    "                               tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "                               preprocessing_keys_to_fns=preprocessing_fns)\n",
    "\n",
    "tfprint(next(iter(dataset.batch(5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map, Filter, Filter, Batch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variety of map, reduce, filter, shuffle operations can be used here\n",
    "# dataset = dataset.<map, filter, reduce>(tf_preprocess_fn)\n",
    "\n",
    "# NOTE: This is lazy batching\n",
    "dataset = dataset.batch(batch_size=128, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or... you can do all of that for train, val and test in _one_ step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv, ..\n",
      "INFO:root:Writing SequenceExample protobufs to : ../ml4ir/applications/ranking/tests/data/csv/tfrecord/train/file_0.tfrecord\n",
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['../ml4ir/applications/ranking/tests/data/csv/tfr\n",
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/validation/file_0.csv, ..\n",
      "INFO:root:Writing SequenceExample protobufs to : ../ml4ir/applications/ranking/tests/data/csv/tfrecord/validation/file_0.tfrecord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['../ml4ir/applications/ranking/tests/data/csv/tfr\n",
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/test/file_0.csv, ..\n",
      "INFO:root:Writing SequenceExample protobufs to : ../ml4ir/applications/ranking/tests/data/csv/tfrecord/test/file_0.tfrecord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['../ml4ir/applications/ranking/tests/data/csv/tfr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n",
      "<BatchDataset shapes: ({query_id: (128, 1), rank: (128, 1), text_match_score: (128, 1), page_views_score: (128, 1), quality_score: (128, 1), name_match: (128, 1), query_text: (128, 1), domain_id: (128, 1), domain_name: (128, 1)}, (128, 1)), types: ({query_id: tf.string, rank: tf.int64, text_match_score: tf.float32, page_views_score: tf.float32, quality_score: tf.float32, name_match: tf.float32, query_text: tf.string, domain_id: tf.int64, domain_name: tf.string}, tf.int64)>\n",
      "<BatchDataset shapes: ({query_id: (128, 1), rank: (128, 1), text_match_score: (128, 1), page_views_score: (128, 1), quality_score: (128, 1), name_match: (128, 1), query_text: (128, 1), domain_id: (128, 1), domain_name: (128, 1)}, (128, 1)), types: ({query_id: tf.string, rank: tf.int64, text_match_score: tf.float32, page_views_score: tf.float32, quality_score: tf.float32, name_match: tf.float32, query_text: tf.string, domain_id: tf.int64, domain_name: tf.string}, tf.int64)>\n",
      "<BatchDataset shapes: ({query_id: (128, 1), rank: (128, 1), text_match_score: (128, 1), page_views_score: (128, 1), quality_score: (128, 1), name_match: (128, 1), query_text: (128, 1), domain_id: (128, 1), domain_name: (128, 1)}, (128, 1)), types: ({query_id: tf.string, rank: tf.int64, text_match_score: tf.float32, page_views_score: tf.float32, quality_score: tf.float32, name_match: tf.float32, query_text: tf.string, domain_id: tf.int64, domain_name: tf.string}, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.data.relevance_dataset import RelevanceDataset\n",
    "from ml4ir.base.config.keys import DataFormatKey\n",
    "\n",
    "relevance_dataset = RelevanceDataset(\n",
    "        data_dir=CSV_DATA_DIR,\n",
    "        data_format=DataFormatKey.CSV,\n",
    "        feature_config=feature_config,\n",
    "        tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "        batch_size=128,\n",
    "        preprocessing_keys_to_fns=preprocessing_fns,\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "tfprint(relevance_dataset.train)\n",
    "tfprint(relevance_dataset.validation)\n",
    "tfprint(relevance_dataset.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define a model, already!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/model_framework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Define the Interaction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4ir.base.model.scoring.interaction_model import InteractionModel, UnivariateInteractionModel\n",
    "from ml4ir.base.config.keys import TFRecordTypeKey\n",
    "from tensorflow import feature_column\n",
    "\n",
    "# Define custom feature layer ops\n",
    "def custom_categorical_embedding(feature_tensor, feature_info, **kwargs):\n",
    "    \"\"\"\n",
    "    Converts input integer tensor into categorical embedding.\n",
    "    Works by converting the categorical indices in the input feature_tensor,\n",
    "    represented as integer values, into categorical embeddings based on the feature_info.\n",
    "\n",
    "    Args:\n",
    "        feature_tensor: int feature tensor\n",
    "        feature_info: Dictionary representing the configuration parameters for the specific feature from the FeatureConfig\n",
    "\n",
    "    Returns:\n",
    "        categorical embedding for the input feature_tensor\n",
    "\n",
    "    Args under feature_layer_info:\n",
    "        num_buckets: int; Maximum number of categorical values\n",
    "        default_value: int; default value to be assigned to indices out of the num_buckets range\n",
    "        embedding_size: int; dimension size of the categorical embedding\n",
    "\n",
    "    NOTE:\n",
    "    string based categorical features should already be converted into numeric indices\n",
    "    \"\"\"\n",
    "    CATEGORICAL_VARIABLE = \"categorical_variable\"\n",
    "    feature_layer_info = feature_info.get(\"feature_layer_info\")\n",
    "\n",
    "    categorical_fc = feature_column.categorical_column_with_identity(\n",
    "        CATEGORICAL_VARIABLE,\n",
    "        num_buckets=feature_layer_info[\"args\"][\"num_buckets\"],\n",
    "        default_value=feature_layer_info[\"args\"].get(\"default_value\", None),\n",
    "    )\n",
    "    embedding_fc = feature_column.embedding_column(\n",
    "        categorical_fc, dimension=feature_layer_info[\"args\"][\"embedding_size\"]\n",
    "    )\n",
    "\n",
    "    embedding = layers.DenseFeatures(\n",
    "        embedding_fc,\n",
    "        name=\"{}_embedding\".format(feature_info.get(\"node_name\", feature_info[\"name\"])),\n",
    "    )({CATEGORICAL_VARIABLE: feature_tensor})\n",
    "    embedding = tf.expand_dims(embedding, axis=1)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "feature_layer_fns = {\n",
    "    \"custom_categorical_embedding\": custom_categorical_embedding,\n",
    "}\n",
    "\n",
    "interaction_model: InteractionModel = UnivariateInteractionModel(\n",
    "                                            feature_config=feature_config,\n",
    "                                            feature_layer_keys_to_fns=feature_layer_fns,\n",
    "                                            tfrecord_type=TFRecordTypeKey.EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{\n",
      "    \"architecture_key\": \"dnn\",\n",
      "    \"layers\": [\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"first_dense\",\n",
      "            \"units\": 256,\n",
      "            \"activation\": \"relu\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dropout\",\n",
      "            \"name\": \"first_dropout\",\n",
      "            \"rate\": 0.0\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"second_dense\",\n",
      "            \"units\": 64,\n",
      "            \"activation\": \"relu\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dropout\",\n",
      "            \"name\": \"second_dropout\",\n",
      "            \"rate\": 0.0\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"final_dense\",\n",
      "            \"units\": 1,\n",
      "            \"activation\": null\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.model.scoring.scoring_model import ScorerBase, RelevanceScorer\n",
    "from ml4ir.base.model.losses.loss_base import RelevanceLossBase\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "class MyCustomLoss(RelevanceLossBase):\n",
    "    def get_loss_fn(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Define a sigmoid cross entropy loss\n",
    "        Additionally can pass in record positions to handle positional bias\n",
    "\n",
    "        \"\"\"\n",
    "        bce = losses.BinaryCrossentropy(reduction=losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "        mask = kwargs.get(\"mask\")\n",
    "\n",
    "        def _loss_fn(y_true, y_pred):\n",
    "            # NOTE: Can use any of the metadata features to qualify your loss here\n",
    "            return bce(y_true, y_pred)\n",
    "\n",
    "        return _loss_fn\n",
    "\n",
    "    def get_final_activation_op(self, output_name):\n",
    "        return lambda logits, mask: layers.Activation(\"sigmoid\", name=output_name)(logits)\n",
    "\n",
    "scorer: ScorerBase = RelevanceScorer.from_model_config_file(\n",
    "    model_config_file='../ml4ir/base/config/default_model_config.yaml',\n",
    "    interaction_model=interaction_model,\n",
    "    loss=MyCustomLoss(),\n",
    "    output_name=\"relevance_score\")\n",
    "    \n",
    "logger.info(json.dumps(scorer.model_config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics as kmetrics\n",
    "\n",
    "# metrics = ['binary_accuracy', kmetrics.Precision(name='precision')]\n",
    "metrics = ['binary_accuracy', kmetrics.Precision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Optimizer\n",
    "from ml4ir.base.model.optimizer import get_optimizer\n",
    "from ml4ir.base.config.keys import OptimizerKey\n",
    "\n",
    "optimizer: Optimizer = get_optimizer(\n",
    "                optimizer_key=OptimizerKey.ADAM,\n",
    "                learning_rate=0.01,\n",
    "                learning_rate_decay=0.94,\n",
    "                learning_rate_decay_steps=1000,\n",
    "                gradient_clip_value=50,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now... let's put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:root:Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "query_text (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DecodePaddedRaw_6 ( [(None, 1, 20)]      0           query_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "domain_name (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 20)]         0           tf_op_layer_DecodePaddedRaw_6[0][\n",
      "__________________________________________________________________________________________________\n",
      "domain_id (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vocab_lookup_2 (VocabLookup)    (None, 1)            0           domain_name[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 20, 128)      32768       tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "domain_id_embedding (DenseFeatu (None, 64)           512         domain_id[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "domain_name_embedding (DenseFea (None, 64)           384         vocab_lookup_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "page_views_score (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quality_score (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 128)          98816       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "text_match_score (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_33 (Tens [(None, 1, 64)]      0           domain_id_embedding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_34 (Tens [(None, 1, 64)]      0           domain_name_embedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_30 (Tens [(None, 1, 1)]       0           page_views_score[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_31 (Tens [(None, 1, 1)]       0           quality_score[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_32 (Tens [(None, 1, 128)]     0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_29 (Tens [(None, 1, 1)]       0           text_match_score[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_train_features_2 (T [(None, 1, 259)]     0           tf_op_layer_ExpandDims_33[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_34[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_30[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_31[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_32[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "first_dense (Dense)             (None, 1, 256)       66560       tf_op_layer_train_features_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "first_dropout (Dropout)         (None, 1, 256)       0           first_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "second_dense (Dense)            (None, 1, 64)        16448       first_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "second_dropout (Dropout)        (None, 1, 64)        0           second_dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dense (Dense)             (None, 1, 1)         65          second_dropout[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_2 (TensorFl [(None, 1)]          0           final_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "name_match (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "query_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rank (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "relevance_score (Activation)    (None, 1)            0           tf_op_layer_Squeeze_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 215,553\n",
      "Trainable params: 215,553\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.model.relevance_model import RelevanceModel\n",
    "from ml4ir.base.config.keys import OptimizerKey\n",
    "\n",
    "relevance_model = RelevanceModel(\n",
    "        feature_config=feature_config,\n",
    "        scorer=scorer,\n",
    "        metrics=metrics,\n",
    "        optimizer=optimizer,\n",
    "        tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "        output_name=\"relevance_score\",\n",
    "        logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training Model\n",
      "INFO:root:Starting Epoch : 1\n",
      "INFO:root:{}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 1 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.6826525, 'binary_accuracy': 0.703125, 'precision_2': 0.35}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      1/Unknown - 7s 7s/step - loss: 0.6827 - binary_accuracy: 0.7031 - precision_2: 0.3500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.231601). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25/Unknown - 9s 377ms/step - loss: 0.5766 - binary_accuracy: 0.7347 - precision_2: 0.3500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 1 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.56843483, 'binary_accuracy': 0.73467547, 'precision_2': 0.35}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     44/Unknown - 11s 249ms/step - loss: 0.5709 - binary_accuracy: 0.7342 - precision_2: 0.3600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.73899, saving model to ../models/checkpoint.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/checkpoint.tf/assets\n",
      "INFO:root:End of Epoch 1\n",
      "INFO:root:{'loss': 0.5708632137287747, 'binary_accuracy': 0.73419744, 'precision_2': 0.36, 'val_loss': 0.5543010085821152, 'val_binary_accuracy': 0.7389915, 'val_precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 50s 1s/step - loss: 0.5709 - binary_accuracy: 0.7342 - precision_2: 0.3600 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_precision_2: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 2\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 2 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.54853475, 'binary_accuracy': 0.75, 'precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5552 - binary_accuracy: 0.7366 - precision_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 2 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.5607991, 'binary_accuracy': 0.7364784, 'precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5531 - binary_accuracy: 0.7353 - precision_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_binary_accuracy improved from 0.73899 to 0.73917, saving model to ../models/checkpoint.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/checkpoint.tf/assets\n",
      "INFO:root:End of Epoch 2\n",
      "INFO:root:{'loss': 0.5534106140786951, 'binary_accuracy': 0.7354403, 'precision_2': 0.0, 'val_loss': 0.5538883398879658, 'val_binary_accuracy': 0.73916906, 'val_precision_2': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 36s 817ms/step - loss: 0.5534 - binary_accuracy: 0.7354 - precision_2: 0.0000e+00 - val_loss: 0.5539 - val_binary_accuracy: 0.7392 - val_precision_2: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 3\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 3 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.55543643, 'binary_accuracy': 0.75, 'precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5539 - binary_accuracy: 0.7366 - precision_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 3 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.5644777, 'binary_accuracy': 0.7364784, 'precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5528 - binary_accuracy: 0.7353 - precision_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n",
      "INFO:root:End of Epoch 3\n",
      "INFO:root:{'loss': 0.5531194724819877, 'binary_accuracy': 0.7354403, 'precision_2': 0.0, 'val_loss': 0.5663753246719186, 'val_binary_accuracy': 0.7354403, 'val_precision_2': 0.115384616}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.73917\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 5s 112ms/step - loss: 0.5531 - binary_accuracy: 0.7354 - precision_2: 0.0000e+00 - val_loss: 0.5664 - val_binary_accuracy: 0.7354 - val_precision_2: 0.1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 4\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 4 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.5599993, 'binary_accuracy': 0.75, 'precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5492 - binary_accuracy: 0.7366 - precision_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 4 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.5672796, 'binary_accuracy': 0.7364784, 'precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5497 - binary_accuracy: 0.7353 - precision_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n",
      "INFO:root:End of Epoch 4\n",
      "INFO:root:{'loss': 0.5499490587548777, 'binary_accuracy': 0.7354403, 'precision_2': 0.0, 'val_loss': 0.5504594336856495, 'val_binary_accuracy': 0.7389915, 'val_precision_2': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.73917\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 6s 131ms/step - loss: 0.5499 - binary_accuracy: 0.7354 - precision_2: 0.0000e+00 - val_loss: 0.5505 - val_binary_accuracy: 0.7390 - val_precision_2: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Completed training model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "if not os.path.exists('../logs'):\n",
    "    os.makedirs('../logs')\n",
    "\n",
    "relevance_model.fit(relevance_dataset, \n",
    "                    num_epochs=5, \n",
    "                    models_dir='../models',\n",
    "                    logs_dir='../logs',\n",
    "                    monitor_metric='val_binary_accuracy',\n",
    "                    monitor_mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's save the model(...and don't forget about serving signatures)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/saved_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/pointwise_ranking_demo/final/default/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/pointwise_ranking_demo/final/tfrecord/assets\n",
      "INFO:root:Final model saved to : ../models/pointwise_ranking_demo/final\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = '../models/pointwise_ranking_demo'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    \n",
    "relevance_model.save(\n",
    "    models_dir=MODEL_DIR,\n",
    "    preprocessing_keys_to_fns=preprocessing_fns,\n",
    "    required_fields_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the model for some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully loaded SavedModel from ../models/pointwise_ranking_demo/final/default/\n",
      "WARNING:root:Retraining is not yet supported. Model is loaded with compile=False\n",
      "INFO:root:Is Keras model? True\n",
      "INFO:root:Is compiled? False\n",
      "INFO:root:Finished predicting scores for 25 batches\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>clicked</th>\n",
       "      <th>rank</th>\n",
       "      <th>name_match</th>\n",
       "      <th>query_text</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b'query_312'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'lbdavmmr04ydc'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.234175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>b'query_1029'</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'76scfjnwz'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.255646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b'query_235'</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yp7v0xfio'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.146192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>b'query_1081'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'pvsvzgydu'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.460975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b'query_727'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'5ampmdi9q'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.236239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>b'query_743'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'u6985gdq'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.192888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>b'query_1277'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'hu8oqpb'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.309300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>b'query_1030'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'n8mqju'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.398232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>b'query_156'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b's5v7a5u5nf'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.245318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>b'query_1270'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'93ppz'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.212614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>b'query_452'</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'b0cwixhhk'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.297863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b'query_1051'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'j4y3ew'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.200782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>b'query_1222'</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'kq71sbh241xb'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.316380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>b'query_1015'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'upkcu8l'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.287628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>b'query_853'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'4i6lrvx68sptn5s'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.303691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>b'query_218'</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'6314ict'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.302341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>b'query_776'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'011pkgzq'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.166851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b'query_512'</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2yy38zdzw'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.232349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>b'query_177'</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'8n9ksu'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.262419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>b'query_1191'</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'w8kn75j'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.247455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>b'query_283'</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b't16h5'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.172743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>b'query_72'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2adtmtq889'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.478363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>b'query_74'</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'eqkomy'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.318705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>b'query_1494'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'kwkn79mft45vtdh'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>b'query_1346'</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'mi60vrzur'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.190887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          query_id  clicked  rank  name_match          query_text  \\\n",
       "21    b'query_312'        1     1         0.0    b'lbdavmmr04ydc'   \n",
       "97   b'query_1029'        1     4         0.0        b'76scfjnwz'   \n",
       "12    b'query_235'        0     2         0.0        b'yp7v0xfio'   \n",
       "50   b'query_1081'        0     3         0.0        b'pvsvzgydu'   \n",
       "26    b'query_727'        1     1         0.0        b'5ampmdi9q'   \n",
       "55    b'query_743'        0     1         1.0         b'u6985gdq'   \n",
       "54   b'query_1277'        0     5         1.0          b'hu8oqpb'   \n",
       "106  b'query_1030'        0     3         1.0           b'n8mqju'   \n",
       "34    b'query_156'        0     3         0.0       b's5v7a5u5nf'   \n",
       "106  b'query_1270'        1     1         0.0            b'93ppz'   \n",
       "75    b'query_452'        0     6         0.0        b'b0cwixhhk'   \n",
       "22   b'query_1051'        0     5         0.0           b'j4y3ew'   \n",
       "78   b'query_1222'        0     6         0.0     b'kq71sbh241xb'   \n",
       "114  b'query_1015'        0     5         1.0          b'upkcu8l'   \n",
       "122   b'query_853'        0     5         1.0  b'4i6lrvx68sptn5s'   \n",
       "107   b'query_218'        1     3         1.0          b'6314ict'   \n",
       "35    b'query_776'        0     5         1.0         b'011pkgzq'   \n",
       "10    b'query_512'        0     4         0.0        b'2yy38zdzw'   \n",
       "122   b'query_177'        0     4         0.0           b'8n9ksu'   \n",
       "48   b'query_1191'        0     4         0.0          b'w8kn75j'   \n",
       "86    b'query_283'        1     2         1.0            b't16h5'   \n",
       "102    b'query_72'        0     5         0.0       b'2adtmtq889'   \n",
       "106    b'query_74'        1     2         1.0           b'eqkomy'   \n",
       "32   b'query_1494'        0     1         1.0  b'kwkn79mft45vtdh'   \n",
       "43   b'query_1346'        0     2         1.0        b'mi60vrzur'   \n",
       "\n",
       "     domain_name  relevance_score  \n",
       "21   b'domain_2'         0.234175  \n",
       "97   b'domain_4'         0.255646  \n",
       "12   b'domain_0'         0.146192  \n",
       "50   b'domain_1'         0.460975  \n",
       "26   b'domain_2'         0.236239  \n",
       "55   b'domain_3'         0.192888  \n",
       "54   b'domain_2'         0.309300  \n",
       "106  b'domain_0'         0.398232  \n",
       "34   b'domain_1'         0.245318  \n",
       "106  b'domain_0'         0.212614  \n",
       "75   b'domain_2'         0.297863  \n",
       "22   b'domain_1'         0.200782  \n",
       "78   b'domain_2'         0.316380  \n",
       "114  b'domain_0'         0.287628  \n",
       "122  b'domain_3'         0.303691  \n",
       "107  b'domain_3'         0.302341  \n",
       "35   b'domain_1'         0.166851  \n",
       "10   b'domain_2'         0.232349  \n",
       "122  b'domain_2'         0.262419  \n",
       "48   b'domain_1'         0.247455  \n",
       "86   b'domain_3'         0.172743  \n",
       "102  b'domain_2'         0.478363  \n",
       "106  b'domain_4'         0.318705  \n",
       "32   b'domain_4'         0.127900  \n",
       "43   b'domain_1'         0.190887  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4ir.base.config.keys import TFRecordTypeKey\n",
    "\n",
    "relevance_model = RelevanceModel(\n",
    "    feature_config=feature_config,\n",
    "    tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "    model_file=os.path.join(MODEL_DIR, 'final/default/'),\n",
    "    logger=logger,\n",
    "    output_name=\"relevance_score\"\n",
    ")\n",
    "\n",
    "logger.info(\"Is Keras model? {}\".format(isinstance(relevance_model.model, tf.keras.Model)))\n",
    "logger.info(\"Is compiled? {}\".format(relevance_model.is_compiled))\n",
    "\n",
    "relevance_model.predict(test_dataset=relevance_dataset.test).sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how the TFRecord serving signature works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Example proto: \n",
      "b'\\n\\xf7\\x01\\n\\x1c\\n\\x10page_views_score\\x12\\x08\\x12\\x06\\n\\x04]\\x04G>\\n\\x16\\n\\nname_match\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80?\\n\\x19\\n\\rquality_score\\x12\\x08\\x12\\x06\\n\\x04\\x9b \\x9a>\\n\\x17\\n\\x08query_id\\x12\\x0b\\n\\t\\n\\x07query_1\\n\\x1b\\n\\x0bdomain_name\\x12\\x0c\\n\\n\\n\\x08domain_1\\n\\r\\n\\x04rank\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x1b\\n\\nquery_text\\x12\\r\\n\\x0b\\n\\tLVA3934GV\\n\\x10\\n\\x07clicked\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x1c\\n\\x10text_match_score\\x12\\x08\\x12\\x06\\n\\x044\\xb4\\x19?\\n\\x12\\n\\tdomain_id\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      "INFO:root:\n",
      "\n",
      "\n",
      "Predictions:\n",
      "INFO:root:{'relevance_score': <tf.Tensor: id=469044, shape=(10, 1), dtype=float32, numpy=\n",
      "array([[0.42908183],\n",
      "       [0.46207318],\n",
      "       [0.24165526],\n",
      "       [0.42101735],\n",
      "       [0.42176935],\n",
      "       [0.23088714],\n",
      "       [0.42101735],\n",
      "       [0.46448255],\n",
      "       [0.46483183],\n",
      "       [0.46320197]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models as kmodels\n",
    "from tensorflow import data\n",
    "\n",
    "model = kmodels.load_model(\n",
    "    os.path.join(MODEL_DIR, 'final/tfrecord/'),\n",
    "    compile=False)\n",
    "infer_fn = model.signatures[\"serving_tfrecord\"]\n",
    "\n",
    "dataset = data.TFRecordDataset(\n",
    "    glob.glob(os.path.join(CSV_DATA_DIR, \"tfrecord\", \"test\", \"*.tfrecord\")))\n",
    "protos = next(iter(dataset.batch(10)))\n",
    "\n",
    "logger.info(\"Example proto: \\n{}\".format(protos[0]))\n",
    "\n",
    "logger.info(\"\\n\\n\\nPredictions:\")\n",
    "logger.info(infer_fn(protos=protos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why you should onboard your ML application to ml4ir today!\n",
    "\n",
    "* Consistent code structure and modularization across projects\n",
    "* Scalable TFRecord data pipeline\n",
    "    * Every ML application shouldnt have to reinvent the wheel especially when there is barely any documentation on this.\n",
    "    * Consistent file I/O overall\n",
    "* Consistent library versions across projects\n",
    "    * Easily update versions and validate inference time impact, etc\n",
    "* Common Flowsnake enablement\n",
    "    * We can define _git.soma/MLConfigs_ to track and automatically build docker images through strata from ml4ir.\n",
    "* Unified python  JVM interoperability\n",
    "    * Define integration tests\n",
    "    * Allows us to build generic protobuf creation at runtime\n",
    "* Common training abstraction\n",
    "    * Callbacks : checkpointing, early stopping, tensorboard, etc\n",
    "    * Consistent way to save models\n",
    "        * allows us to have generic deployment code\n",
    "* Shared metrics, losses, layers, etc.\n",
    "* Shared feature processing and feature layers across ML models\n",
    "    * long term: shared NLP toolkit, probability toolkit\n",
    "    * short term: categorical, text embeddings\n",
    "* Build models that can be trained with tight coupling:\n",
    "    * transfer learning\n",
    "    * shared embedding layers\n",
    "    * multi task models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### This is just the `end of the beginning` and we would love to take new passengers on this journey!\n",
    "\n",
    "![thanks](images/thats_all_folks.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "<center>Psst... You can file github issues -> <a href=\"https://github.com/salesforce/ml4ir/issues\">HERE!</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shhh](images/chris_evans_shush.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
