{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ml4ir](https://github.com/salesforce/ml4ir) \n",
    "#### open source, modular, python3, tensorflow2.0 library for IR based ML applications\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/ml4ir.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's load the data and take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Logger is initialized...\n",
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv, ..\n",
      "INFO:root:Loading dataframe from path : ../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv\n",
      "INFO:root:(5676, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>rank</th>\n",
       "      <th>text_match_score</th>\n",
       "      <th>page_views_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>name_match</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>query_0</td>\n",
       "      <td>UQHA3QP4ZVO</td>\n",
       "      <td>1</td>\n",
       "      <td>1.101297</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>query_0</td>\n",
       "      <td>UQHA3QP4ZVO</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380570</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>1</td>\n",
       "      <td>1.024334</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>2</td>\n",
       "      <td>0.821515</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>3</td>\n",
       "      <td>0.821323</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>4</td>\n",
       "      <td>0.821515</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>query_1</td>\n",
       "      <td>8M3NWYX4E6I</td>\n",
       "      <td>5</td>\n",
       "      <td>0.821323</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>domain_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id   query_text  rank  text_match_score  page_views_score  \\\n",
       "4365  query_0  UQHA3QP4ZVO     1          1.101297          0.002044   \n",
       "4366  query_0  UQHA3QP4ZVO     2          0.380570          0.004078   \n",
       "4371  query_1  8M3NWYX4E6I     1          1.024334          0.008686   \n",
       "4368  query_1  8M3NWYX4E6I     2          0.821515          0.200264   \n",
       "4370  query_1  8M3NWYX4E6I     3          0.821323          0.200264   \n",
       "4369  query_1  8M3NWYX4E6I     4          0.821515          0.200264   \n",
       "4367  query_1  8M3NWYX4E6I     5          0.821323          0.200264   \n",
       "\n",
       "      quality_score  domain_id domain_name  name_match  clicked  \n",
       "4365        0.00000          0    domain_0           0        1  \n",
       "4366        0.30103          0    domain_0           0        0  \n",
       "4371        0.30103          1    domain_1           1        1  \n",
       "4368        0.00000          1    domain_1           1        0  \n",
       "4370        0.00000          1    domain_1           0        0  \n",
       "4369        0.00000          1    domain_1           0        0  \n",
       "4367        0.00000          1    domain_1           1        0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4ir.base.io.local_io import LocalIO\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"Logger is initialized...\")\n",
    "\n",
    "# Setup FileIO\n",
    "file_io = LocalIO(logger)\n",
    "\n",
    "# Load data\n",
    "CSV_DATA_DIR = '../ml4ir/applications/ranking/tests/data/csv'\n",
    "\n",
    "df = file_io.read_df_list(glob.glob(os.path.join(CSV_DATA_DIR, \"train\", \"*.csv\")))\n",
    "\n",
    "logger.info(df.shape)\n",
    "\n",
    "df[[c for c in df.columns if c != \"clicked\"] + [\"clicked\"]].sort_values([\"query_id\", \"rank\"]).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define the feature configuration for our data\n",
    "\n",
    "### ... brace yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:{\n",
      "    \"query_key\": {\n",
      "        \"name\": \"query_id\",\n",
      "        \"node_name\": \"query_id\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"string\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"queryId\",\n",
      "            \"required\": false,\n",
      "            \"default_value\": \"\"\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    },\n",
      "    \"label\": {\n",
      "        \"name\": \"clicked\",\n",
      "        \"node_name\": \"clicked\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"name\": \"clicked\",\n",
      "            \"required\": false,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    \"features\": [\n",
      "        {\n",
      "            \"name\": \"rank\",\n",
      "            \"node_name\": \"rank\",\n",
      "            \"trainable\": false,\n",
      "            \"dtype\": \"int64\",\n",
      "            \"log_at_inference\": true,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null\n",
      "            },\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"originalRank\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": 0\n",
      "            },\n",
      "            \"tfrecord_type\": \"sequence\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"text_match_score\",\n",
      "            \"node_name\": \"text_match_score\",\n",
      "            \"trainable\": true,\n",
      "            \"dtype\": \"float\",\n",
      "            \"log_at_inference\": false,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null\n",
      "            },\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"textMatchScore\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": 0.0\n",
      "            },\n",
      "            \"tfrecord_type\": \"sequence\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"page_views_score\",\n",
      "            \"node_name\": \"page_views_score\",\n",
      "            \"trainable\": true,\n",
      "            \"dtype\": \"float\",\n",
      "            \"log_at_inference\": false,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null\n",
      "            },\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"pageViewsScore\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": 0.0\n",
      "            },\n",
      "            \"tfrecord_type\": \"sequence\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"quality_score\",\n",
      "            \"node_name\": \"quality_score\",\n",
      "            \"trainable\": true,\n",
      "            \"dtype\": \"float\",\n",
      "            \"log_at_inference\": false,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null\n",
      "            },\n",
      "            \"preprocessing_info\": [\n",
      "                {\n",
      "                    \"fn\": \"signed_log\",\n",
      "                    \"args\": {\n",
      "                        \"shift\": 1\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"qualityScore\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": 0.0\n",
      "            },\n",
      "            \"tfrecord_type\": \"sequence\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"name_match\",\n",
      "            \"node_name\": \"name_match\",\n",
      "            \"trainable\": false,\n",
      "            \"dtype\": \"float\",\n",
      "            \"log_at_inference\": true,\n",
      "            \"is_secondary_label\": true,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null\n",
      "            },\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"nameMatch\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": 0.0\n",
      "            },\n",
      "            \"tfrecord_type\": \"sequence\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"query_text\",\n",
      "            \"node_name\": \"query_text\",\n",
      "            \"trainable\": true,\n",
      "            \"dtype\": \"string\",\n",
      "            \"log_at_inference\": true,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null,\n",
      "                \"fn\": \"bytes_sequence_to_encoding_bilstm\",\n",
      "                \"args\": {\n",
      "                    \"encoding_type\": \"bilstm\",\n",
      "                    \"encoding_size\": 128,\n",
      "                    \"embedding_size\": 128,\n",
      "                    \"max_length\": 20\n",
      "                }\n",
      "            },\n",
      "            \"preprocessing_info\": [\n",
      "                {\n",
      "                    \"fn\": \"preprocess_text\",\n",
      "                    \"args\": {\n",
      "                        \"remove_punctuation\": true,\n",
      "                        \"to_lower\": true\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"q\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": \"\"\n",
      "            },\n",
      "            \"tfrecord_type\": \"context\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"domain_id\",\n",
      "            \"node_name\": \"domain_id\",\n",
      "            \"trainable\": true,\n",
      "            \"dtype\": \"int64\",\n",
      "            \"log_at_inference\": false,\n",
      "            \"is_group_metric_key\": true,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null,\n",
      "                \"fn\": \"custom_categorical_embedding\",\n",
      "                \"args\": {\n",
      "                    \"num_buckets\": 8,\n",
      "                    \"embedding_size\": 64,\n",
      "                    \"default_value\": null\n",
      "                }\n",
      "            },\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"domainID\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": 0\n",
      "            },\n",
      "            \"tfrecord_type\": \"context\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"domain_name\",\n",
      "            \"node_name\": \"domain_name\",\n",
      "            \"trainable\": true,\n",
      "            \"dtype\": \"string\",\n",
      "            \"log_at_inference\": true,\n",
      "            \"is_group_metric_key\": true,\n",
      "            \"feature_layer_info\": {\n",
      "                \"type\": \"numeric\",\n",
      "                \"shape\": null,\n",
      "                \"fn\": \"categorical_embedding_with_vocabulary_file\",\n",
      "                \"args\": {\n",
      "                    \"vocabulary_file\": \"../ml4ir/applications/ranking/tests/data/config/group_name_vocab_no_id.csv\",\n",
      "                    \"embedding_size\": 64,\n",
      "                    \"default_value\": -1,\n",
      "                    \"num_oov_buckets\": 1\n",
      "                }\n",
      "            },\n",
      "            \"serving_info\": {\n",
      "                \"name\": \"domainName\",\n",
      "                \"required\": true,\n",
      "                \"default_value\": \"\"\n",
      "            },\n",
      "            \"tfrecord_type\": \"context\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "INFO:root:Feature config loaded successfully\n",
      "INFO:root:Trainable Features : \n",
      "text_match_score\n",
      "page_views_score\n",
      "quality_score\n",
      "query_text\n",
      "domain_id\n",
      "domain_name\n",
      "INFO:root:Label : clicked\n",
      "INFO:root:Metadata Features : \n",
      "query_id\n",
      "clicked\n",
      "rank\n",
      "name_match\n"
     ]
    }
   ],
   "source": [
    "# Set up the feature configurations\n",
    "from ml4ir.base.features.feature_config import FeatureConfig, ExampleFeatureConfig\n",
    "from ml4ir.base.config.keys import TFRecordTypeKey\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "feature_config_yaml = '''\n",
    "query_key: \n",
    "  name: query_id\n",
    "  node_name: query_id\n",
    "  trainable: false\n",
    "  dtype: string\n",
    "  log_at_inference: true\n",
    "  feature_layer_info:\n",
    "    type: numeric\n",
    "    shape: null\n",
    "  serving_info:\n",
    "    name: queryId\n",
    "    required: false\n",
    "    default_value: \"\"\n",
    "  tfrecord_type: context\n",
    "label:\n",
    "  name: clicked\n",
    "  node_name: clicked\n",
    "  trainable: false\n",
    "  dtype: int64\n",
    "  log_at_inference: true\n",
    "  feature_layer_info:\n",
    "    type: numeric\n",
    "    shape: null\n",
    "  serving_info:\n",
    "    name: clicked\n",
    "    required: false\n",
    "    default_value: 0\n",
    "  tfrecord_type: sequence\n",
    "features:\n",
    "  - name: rank\n",
    "    node_name: rank\n",
    "    trainable: false\n",
    "    dtype: int64\n",
    "    log_at_inference: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: originalRank\n",
    "      required: true\n",
    "      default_value: 0\n",
    "    tfrecord_type: sequence\n",
    "  - name: text_match_score\n",
    "    node_name: text_match_score\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: textMatchScore\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: page_views_score\n",
    "    node_name: page_views_score\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: pageViewsScore\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: quality_score\n",
    "    node_name: quality_score\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    preprocessing_info:\n",
    "      - fn: signed_log\n",
    "        args:\n",
    "          shift: 1\n",
    "    serving_info:\n",
    "      name: qualityScore\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: name_match\n",
    "    node_name: name_match\n",
    "    trainable: false\n",
    "    dtype: float\n",
    "    log_at_inference: true\n",
    "    is_secondary_label: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      name: nameMatch\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: query_text\n",
    "    node_name: query_text\n",
    "    trainable: true\n",
    "    dtype: string\n",
    "    log_at_inference: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      fn: bytes_sequence_to_encoding_bilstm\n",
    "      args:\n",
    "        encoding_type: bilstm\n",
    "        encoding_size: 128\n",
    "        embedding_size: 128\n",
    "        max_length: 20\n",
    "    preprocessing_info:\n",
    "      - fn: preprocess_text\n",
    "        args:\n",
    "          remove_punctuation: true\n",
    "          to_lower: true\n",
    "    serving_info:\n",
    "      name: q\n",
    "      required: true\n",
    "      default_value: \"\"\n",
    "    tfrecord_type: context\n",
    "  - name: domain_id\n",
    "    node_name: domain_id\n",
    "    trainable: true\n",
    "    dtype: int64\n",
    "    log_at_inference: false\n",
    "    is_group_metric_key: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      fn: custom_categorical_embedding\n",
    "      args:\n",
    "        num_buckets: 8\n",
    "        embedding_size: 64\n",
    "        default_value: null\n",
    "    serving_info:\n",
    "      name: domainID\n",
    "      required: true\n",
    "      default_value: 0\n",
    "    tfrecord_type: context\n",
    "  - name: domain_name\n",
    "    node_name: domain_name\n",
    "    trainable: true\n",
    "    dtype: string\n",
    "    log_at_inference: true\n",
    "    is_group_metric_key: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      # fn: categorical_embedding_with_hash_buckets\n",
    "      # args:\n",
    "      #   num_hash_buckets: 4\n",
    "      #   hash_bucket_size: 64\n",
    "      #   embedding_size: 32\n",
    "      #   merge_mode: concat\n",
    "      fn: categorical_embedding_with_vocabulary_file\n",
    "      args:\n",
    "        vocabulary_file: '../ml4ir/applications/ranking/tests/data/config/group_name_vocab_no_id.csv'\n",
    "        embedding_size: 64\n",
    "        default_value: -1\n",
    "        num_oov_buckets: 1\n",
    "    serving_info:\n",
    "      name: domainName\n",
    "      required: true\n",
    "      default_value: \"\"\n",
    "    tfrecord_type: context\n",
    "'''\n",
    "feature_config: ExampleFeatureConfig = FeatureConfig.get_instance(\n",
    "    tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "    feature_config_dict=yaml.safe_load(feature_config_yaml),\n",
    "    logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords - Examples vs SequenceExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/tfrecords.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to load the data and save awesome TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv, ..\n",
      "INFO:root:Loading dataframe from path : ../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>rank</th>\n",
       "      <th>text_match_score</th>\n",
       "      <th>page_views_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>clicked</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>name_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query_2</td>\n",
       "      <td>MHS7A7RJB1Y4BJT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>domain_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query_2</td>\n",
       "      <td>MHS7A7RJB1Y4BJT</td>\n",
       "      <td>1</td>\n",
       "      <td>1.063190</td>\n",
       "      <td>0.205381</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>domain_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query_5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>6</td>\n",
       "      <td>1.368108</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query_5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>3</td>\n",
       "      <td>1.370628</td>\n",
       "      <td>0.041261</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query_5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>4</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>0.082535</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id       query_text  rank  text_match_score  page_views_score  \\\n",
       "0  query_2  MHS7A7RJB1Y4BJT     2          0.473730          0.000000   \n",
       "1  query_2  MHS7A7RJB1Y4BJT     1          1.063190          0.205381   \n",
       "2  query_5           KNJNWV     6          1.368108          0.030636   \n",
       "3  query_5           KNJNWV     3          1.370628          0.041261   \n",
       "4  query_5           KNJNWV     4          1.366700          0.082535   \n",
       "\n",
       "   quality_score  clicked  domain_id domain_name  name_match  \n",
       "0        0.00000        0          2    domain_2           1  \n",
       "1        0.30103        1          2    domain_2           1  \n",
       "2        0.00000        0          0    domain_0           0  \n",
       "3        0.30103        0          0    domain_0           0  \n",
       "4        0.30103        0          0    domain_0           0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4ir.base.data import tfrecord_writer\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "df = file_io.read_df_list(glob.glob(os.path.join(CSV_DATA_DIR, \"train\", \"*.csv\")))\n",
    "\n",
    "# Save as TFRecord SequenceExample/Example\n",
    "TFRECORD_DIR = '../data/pointwise_ranking_demo/'\n",
    "if not os.path.exists(TFRECORD_DIR):\n",
    "    os.makedirs('../data/pointwise_ranking_demo/')\n",
    "tfrecord_writer.write_from_df(df,\n",
    "                              tfrecord_file=os.path.join(TFRECORD_DIR, 'file_0.tfrecord'),\n",
    "                              feature_config=feature_config,\n",
    "                              tfrecord_type=TFRecordTypeKey.EXAMPLE)\n",
    "\n",
    "# Let's see what it looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TFRecords and add custom preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1 files found under ../data/pointwise_ranking_demo/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n",
      "({'domain_id': [[2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]],\n",
      "  'domain_name': [[\"domain_2\"]\n",
      " [\"domain_2\"]\n",
      " [\"domain_0\"]\n",
      " [\"domain_0\"]\n",
      " [\"domain_0\"]],\n",
      "  'name_match': [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]],\n",
      "  'page_views_score': [[0]\n",
      " [0.205380633]\n",
      " [0.0306360275]\n",
      " [0.0412614979]\n",
      " [0.0825348869]],\n",
      "  'quality_score': [[0]\n",
      " [0.263156295]\n",
      " [0]\n",
      " [0.263156295]\n",
      " [0.263156295]],\n",
      "  'query_id': [[\"query_2\"]\n",
      " [\"query_2\"]\n",
      " [\"query_5\"]\n",
      " [\"query_5\"]\n",
      " [\"query_5\"]],\n",
      "  'query_text': [[\"mhs7a7rjb1y4bjt\"]\n",
      " [\"mhs7a7rjb1y4bjt\"]\n",
      " [\"knjnwv\"]\n",
      " [\"knjnwv\"]\n",
      " [\"knjnwv\"]],\n",
      "  'rank': [[2]\n",
      " [1]\n",
      " [6]\n",
      " [3]\n",
      " [4]],\n",
      "  'text_match_score': [[0.473729521]\n",
      " [1.06319]\n",
      " [1.36810815]\n",
      " [1.37062836]\n",
      " [1.36669993]]},\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]])\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.data import tfrecord_reader\n",
    "from tensorflow import print as tfprint\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def strip_numbers(feature_tensor):\n",
    "    return tf.strings.regex_replace(feature_tensor, \"[0-9]\", \"\")\n",
    "\n",
    "@tf.function\n",
    "def signed_log(feature_tensor, shift=1.):\n",
    "    \"\"\"Signed log\"\"\"\n",
    "    return tf.math.log(\n",
    "                    tf.add(feature_tensor,\n",
    "                    tf.cast(tf.constant(shift),\n",
    "                            tf.float32)\n",
    "                          )\n",
    "                )\n",
    "\n",
    "\n",
    "# Define per instance preprocessing functions\n",
    "preprocessing_fns = {\n",
    "    \"strip_numbers\": strip_numbers,\n",
    "    \"signed_log\": signed_log\n",
    "}\n",
    "\n",
    "# Create a TFRecord dataset\n",
    "dataset = tfrecord_reader.read(data_dir=TFRECORD_DIR,\n",
    "                               feature_config=feature_config,\n",
    "                               tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "                               preprocessing_keys_to_fns=preprocessing_fns,\n",
    "                               file_io=file_io)\n",
    "\n",
    "tfprint(next(iter(dataset.batch(5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map, Filter, Filter, Batch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variety of map, reduce, filter, shuffle operations can be used here\n",
    "# dataset = dataset.<map, filter, reduce>(tf_preprocess_fn)\n",
    "\n",
    "# NOTE: This is lazy batching\n",
    "dataset = dataset.batch(batch_size=128, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or... you can do all of that for train, val and test in _one_ step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1 files found under ../ml4ir/applications/ranking/tests/data/csv/train\n",
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv, ..\n",
      "INFO:root:Loading dataframe from path : ../ml4ir/applications/ranking/tests/data/csv/train/file_0.csv\n",
      "INFO:root:Writing SequenceExample protobufs to : ../ml4ir/applications/ranking/tests/data/csv/tfrecord/train/file_0.tfrecord\n",
      "INFO:root:1 files found under ../ml4ir/applications/ranking/tests/data/csv/tfrecord/train\n",
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['../ml4ir/applications/ranking/tests/data/csv/tfr\n",
      "INFO:root:1 files found under ../ml4ir/applications/ranking/tests/data/csv/validation\n",
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/validation/file_0.csv, ..\n",
      "INFO:root:Loading dataframe from path : ../ml4ir/applications/ranking/tests/data/csv/validation/file_0.csv\n",
      "INFO:root:Writing SequenceExample protobufs to : ../ml4ir/applications/ranking/tests/data/csv/tfrecord/validation/file_0.tfrecord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1 files found under ../ml4ir/applications/ranking/tests/data/csv/tfrecord/validation\n",
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['../ml4ir/applications/ranking/tests/data/csv/tfr\n",
      "INFO:root:1 files found under ../ml4ir/applications/ranking/tests/data/csv/test\n",
      "INFO:root:Reading 1 files from [../ml4ir/applications/ranking/tests/data/csv/test/file_0.csv, ..\n",
      "INFO:root:Loading dataframe from path : ../ml4ir/applications/ranking/tests/data/csv/test/file_0.csv\n",
      "INFO:root:Writing SequenceExample protobufs to : ../ml4ir/applications/ranking/tests/data/csv/tfrecord/test/file_0.tfrecord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1 files found under ../ml4ir/applications/ranking/tests/data/csv/tfrecord/test\n",
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['../ml4ir/applications/ranking/tests/data/csv/tfr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': FixedLenFeature(shape=[], dtype='string', default_value=''), 'clicked': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n",
      "<BatchDataset shapes: ({query_id: (128, 1), rank: (128, 1), text_match_score: (128, 1), page_views_score: (128, 1), quality_score: (128, 1), name_match: (128, 1), query_text: (128, 1), domain_id: (128, 1), domain_name: (128, 1)}, (128, 1)), types: ({query_id: tf.string, rank: tf.int64, text_match_score: tf.float32, page_views_score: tf.float32, quality_score: tf.float32, name_match: tf.float32, query_text: tf.string, domain_id: tf.int64, domain_name: tf.string}, tf.int64)>\n",
      "<BatchDataset shapes: ({query_id: (128, 1), rank: (128, 1), text_match_score: (128, 1), page_views_score: (128, 1), quality_score: (128, 1), name_match: (128, 1), query_text: (128, 1), domain_id: (128, 1), domain_name: (128, 1)}, (128, 1)), types: ({query_id: tf.string, rank: tf.int64, text_match_score: tf.float32, page_views_score: tf.float32, quality_score: tf.float32, name_match: tf.float32, query_text: tf.string, domain_id: tf.int64, domain_name: tf.string}, tf.int64)>\n",
      "<BatchDataset shapes: ({query_id: (128, 1), rank: (128, 1), text_match_score: (128, 1), page_views_score: (128, 1), quality_score: (128, 1), name_match: (128, 1), query_text: (128, 1), domain_id: (128, 1), domain_name: (128, 1)}, (128, 1)), types: ({query_id: tf.string, rank: tf.int64, text_match_score: tf.float32, page_views_score: tf.float32, quality_score: tf.float32, name_match: tf.float32, query_text: tf.string, domain_id: tf.int64, domain_name: tf.string}, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.data.relevance_dataset import RelevanceDataset\n",
    "from ml4ir.base.config.keys import DataFormatKey\n",
    "\n",
    "relevance_dataset = RelevanceDataset(\n",
    "        data_dir=CSV_DATA_DIR,\n",
    "        data_format=DataFormatKey.CSV,\n",
    "        feature_config=feature_config,\n",
    "        tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "        batch_size=128,\n",
    "        preprocessing_keys_to_fns=preprocessing_fns,\n",
    "        file_io=file_io,\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "tfprint(relevance_dataset.train)\n",
    "tfprint(relevance_dataset.validation)\n",
    "tfprint(relevance_dataset.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define a model, already!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/model_framework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Define the Interaction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4ir.base.model.scoring.interaction_model import InteractionModel, UnivariateInteractionModel\n",
    "from ml4ir.base.config.keys import TFRecordTypeKey\n",
    "from tensorflow import feature_column\n",
    "\n",
    "# Define custom feature layer ops\n",
    "def custom_categorical_embedding(feature_tensor, feature_info, **kwargs):\n",
    "    \"\"\"\n",
    "    Converts input integer tensor into categorical embedding.\n",
    "    Works by converting the categorical indices in the input feature_tensor,\n",
    "    represented as integer values, into categorical embeddings based on the feature_info.\n",
    "\n",
    "    Args:\n",
    "        feature_tensor: int feature tensor\n",
    "        feature_info: Dictionary representing the configuration parameters for the specific feature from the FeatureConfig\n",
    "\n",
    "    Returns:\n",
    "        categorical embedding for the input feature_tensor\n",
    "\n",
    "    Args under feature_layer_info:\n",
    "        num_buckets: int; Maximum number of categorical values\n",
    "        default_value: int; default value to be assigned to indices out of the num_buckets range\n",
    "        embedding_size: int; dimension size of the categorical embedding\n",
    "\n",
    "    NOTE:\n",
    "    string based categorical features should already be converted into numeric indices\n",
    "    \"\"\"\n",
    "    CATEGORICAL_VARIABLE = \"categorical_variable\"\n",
    "    feature_layer_info = feature_info.get(\"feature_layer_info\")\n",
    "\n",
    "    categorical_fc = feature_column.categorical_column_with_identity(\n",
    "        CATEGORICAL_VARIABLE,\n",
    "        num_buckets=feature_layer_info[\"args\"][\"num_buckets\"],\n",
    "        default_value=feature_layer_info[\"args\"].get(\"default_value\", None),\n",
    "    )\n",
    "    embedding_fc = feature_column.embedding_column(\n",
    "        categorical_fc, dimension=feature_layer_info[\"args\"][\"embedding_size\"]\n",
    "    )\n",
    "\n",
    "    embedding = layers.DenseFeatures(\n",
    "        embedding_fc,\n",
    "        name=\"{}_embedding\".format(feature_info.get(\"node_name\", feature_info[\"name\"])),\n",
    "    )({CATEGORICAL_VARIABLE: feature_tensor})\n",
    "    embedding = tf.expand_dims(embedding, axis=1)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "feature_layer_fns = {\n",
    "    \"custom_categorical_embedding\": custom_categorical_embedding,\n",
    "}\n",
    "\n",
    "interaction_model: InteractionModel = UnivariateInteractionModel(\n",
    "                                            feature_config=feature_config,\n",
    "                                            feature_layer_keys_to_fns=feature_layer_fns,\n",
    "                                            tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "                                            file_io=file_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading YAML file from : ../ml4ir/base/config/default_model_config.yaml\n",
      "INFO:root:{\n",
      "    \"architecture_key\": \"dnn\",\n",
      "    \"layers\": [\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"first_dense\",\n",
      "            \"units\": 256,\n",
      "            \"activation\": \"relu\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dropout\",\n",
      "            \"name\": \"first_dropout\",\n",
      "            \"rate\": 0.0\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"second_dense\",\n",
      "            \"units\": 64,\n",
      "            \"activation\": \"relu\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dropout\",\n",
      "            \"name\": \"second_dropout\",\n",
      "            \"rate\": 0.0\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"final_dense\",\n",
      "            \"units\": 1,\n",
      "            \"activation\": null\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.model.scoring.scoring_model import ScorerBase, RelevanceScorer\n",
    "from ml4ir.base.model.losses.loss_base import RelevanceLossBase\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "class MyCustomLoss(RelevanceLossBase):\n",
    "    def get_loss_fn(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Define a sigmoid cross entropy loss\n",
    "        Additionally can pass in record positions to handle positional bias\n",
    "\n",
    "        \"\"\"\n",
    "        bce = losses.BinaryCrossentropy(reduction=losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "        mask = kwargs.get(\"mask\")\n",
    "\n",
    "        def _loss_fn(y_true, y_pred):\n",
    "            # NOTE: Can use any of the metadata features to qualify your loss here\n",
    "            return bce(y_true, y_pred)\n",
    "\n",
    "        return _loss_fn\n",
    "\n",
    "    def get_final_activation_op(self, output_name):\n",
    "        return lambda logits, mask: layers.Activation(\"sigmoid\", name=output_name)(logits)\n",
    "\n",
    "scorer: ScorerBase = RelevanceScorer.from_model_config_file(\n",
    "    model_config_file='../ml4ir/base/config/default_model_config.yaml',\n",
    "    interaction_model=interaction_model,\n",
    "    loss=MyCustomLoss(),\n",
    "    output_name=\"relevance_score\",\n",
    "    file_io=file_io)\n",
    "    \n",
    "logger.info(json.dumps(scorer.model_config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics as kmetrics\n",
    "\n",
    "metrics = ['binary_accuracy', kmetrics.Precision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Optimizer\n",
    "from ml4ir.base.model.optimizer import get_optimizer\n",
    "from ml4ir.base.config.keys import OptimizerKey\n",
    "\n",
    "optimizer: Optimizer = get_optimizer(\n",
    "                optimizer_key=OptimizerKey.ADAM,\n",
    "                learning_rate=0.01,\n",
    "                learning_rate_decay=0.94,\n",
    "                learning_rate_decay_steps=1000,\n",
    "                gradient_clip_value=50,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now... let's put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "INFO:root:Loading dataframe from path : ../ml4ir/applications/ranking/tests/data/config/group_name_vocab_no_id.csv\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:root:Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "query_text (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DecodePaddedRaw_2 ( [(None, 1, 20)]      0           query_text[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "domain_name (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_3 (TensorFl [(None, 20)]         0           tf_op_layer_DecodePaddedRaw_2[0][\n",
      "__________________________________________________________________________________________________\n",
      "domain_id (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vocab_lookup_1 (VocabLookup)    (None, 1)            0           domain_name[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 128)      32768       tf_op_layer_Squeeze_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "domain_id_embedding (DenseFeatu (None, 64)           512         domain_id[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "domain_name_embedding (DenseFea (None, 64)           384         vocab_lookup_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "page_views_score (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quality_score (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 128)          98816       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "text_match_score (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_15 (Tens [(None, 1, 64)]      0           domain_id_embedding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_16 (Tens [(None, 1, 64)]      0           domain_name_embedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_12 (Tens [(None, 1, 1)]       0           page_views_score[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_13 (Tens [(None, 1, 1)]       0           quality_score[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_14 (Tens [(None, 1, 128)]     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_11 (Tens [(None, 1, 1)]       0           text_match_score[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_train_features_1 (T [(None, 1, 259)]     0           tf_op_layer_ExpandDims_15[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_16[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_12[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_13[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_14[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "first_dense (Dense)             (None, 1, 256)       66560       tf_op_layer_train_features_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "first_dropout (Dropout)         (None, 1, 256)       0           first_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "second_dense (Dense)            (None, 1, 64)        16448       first_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "second_dropout (Dropout)        (None, 1, 64)        0           second_dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dense (Dense)             (None, 1, 1)         65          second_dropout[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_4 (TensorFl [(None, 1)]          0           final_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "name_match (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "query_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rank (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "relevance_score (Activation)    (None, 1)            0           tf_op_layer_Squeeze_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 215,553\n",
      "Trainable params: 215,553\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.base.model.relevance_model import RelevanceModel\n",
    "from ml4ir.base.config.keys import OptimizerKey\n",
    "\n",
    "relevance_model = RelevanceModel(\n",
    "        feature_config=feature_config,\n",
    "        scorer=scorer,\n",
    "        metrics=metrics,\n",
    "        optimizer=optimizer,\n",
    "        tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "        output_name=\"relevance_score\",\n",
    "        file_io=file_io,\n",
    "        logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training Model\n",
      "INFO:root:Starting Epoch : 1\n",
      "INFO:root:{}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 1 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.69674414, 'binary_accuracy': 0.4296875, 'precision_1': 0.25882354}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      1/Unknown - 5s 5s/step - loss: 0.6967 - binary_accuracy: 0.4297 - precision_1: 0.2588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.182202). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25/Unknown - 7s 286ms/step - loss: 0.5759 - binary_accuracy: 0.7237 - precision_1: 0.2588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 1 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.56551516, 'binary_accuracy': 0.72415864, 'precision_1': 0.25882354}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     44/Unknown - 9s 194ms/step - loss: 0.5689 - binary_accuracy: 0.7275 - precision_1: 0.3043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.73899, saving model to ../models/checkpoint.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/checkpoint.tf/assets\n",
      "INFO:root:End of Epoch 1\n",
      "INFO:root:{'loss': 0.5689313980666074, 'binary_accuracy': 0.7274503, 'precision_1': 0.3043478, 'val_loss': 0.552667730233886, 'val_binary_accuracy': 0.7389915, 'val_precision_1': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 44s 994ms/step - loss: 0.5689 - binary_accuracy: 0.7275 - precision_1: 0.3043 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_precision_1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 2\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 2 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.5493647, 'binary_accuracy': 0.75, 'precision_1': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5535 - binary_accuracy: 0.7366 - precision_1: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 2 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.5673709, 'binary_accuracy': 0.7364784, 'precision_1': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5517 - binary_accuracy: 0.7351 - precision_1: 0.4966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_binary_accuracy improved from 0.73899 to 0.73917, saving model to ../models/checkpoint.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/checkpoint.tf/assets\n",
      "INFO:root:End of Epoch 2\n",
      "INFO:root:{'loss': 0.5520298013632948, 'binary_accuracy': 0.73508525, 'precision_1': 0.49315068, 'val_loss': 0.5505776676264676, 'val_binary_accuracy': 0.73916906, 'val_precision_1': 0.5081967}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 50s 1s/step - loss: 0.5520 - binary_accuracy: 0.7351 - precision_1: 0.4932 - val_loss: 0.5506 - val_binary_accuracy: 0.7392 - val_precision_1: 0.5082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 3\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 3 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.5579562, 'binary_accuracy': 0.7578125, 'precision_1': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5525 - binary_accuracy: 0.7384 - precision_1: 0.6154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 3 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.56737053, 'binary_accuracy': 0.73828125, 'precision_1': 0.61538464}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5513 - binary_accuracy: 0.7366 - precision_1: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n",
      "INFO:root:End of Epoch 3\n",
      "INFO:root:{'loss': 0.5517122711647641, 'binary_accuracy': 0.7365057, 'precision_1': 0.5833333, 'val_loss': 0.5551647408442064, 'val_binary_accuracy': 0.73881394, 'val_precision_1': 0.4888889}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.73917\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 5s 112ms/step - loss: 0.5517 - binary_accuracy: 0.7365 - precision_1: 0.5833 - val_loss: 0.5552 - val_binary_accuracy: 0.7388 - val_precision_1: 0.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 4\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 4 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.55204946, 'binary_accuracy': 0.7578125, 'precision_1': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5468 - binary_accuracy: 0.7362 - precision_1: 0.3333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 4 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.56661344, 'binary_accuracy': 0.73617786, 'precision_1': 0.33333334}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5457 - binary_accuracy: 0.7338 - precision_1: 0.4545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n",
      "INFO:root:End of Epoch 4\n",
      "INFO:root:{'loss': 0.5459608997810971, 'binary_accuracy': 0.7338423, 'precision_1': 0.45054945, 'val_loss': 0.5523919706994836, 'val_binary_accuracy': 0.73668325, 'val_precision_1': 0.46242774}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.73917\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 6s 140ms/step - loss: 0.5460 - binary_accuracy: 0.7338 - precision_1: 0.4505 - val_loss: 0.5524 - val_binary_accuracy: 0.7367 - val_precision_1: 0.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Completed training model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "if not os.path.exists('../logs'):\n",
    "    os.makedirs('../logs')\n",
    "\n",
    "relevance_model.fit(relevance_dataset, \n",
    "                    num_epochs=5, \n",
    "                    models_dir='../models',\n",
    "                    logs_dir='../logs',\n",
    "                    monitor_metric='val_binary_accuracy',\n",
    "                    monitor_mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's save the model(...and don't forget about serving signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/saved_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/pointwise_ranking_demo/final/default/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rank': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'text_match_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'page_views_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'quality_score': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'name_match': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_text': FixedLenFeature(shape=[], dtype='string', default_value=''), 'domain_id': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'domain_name': FixedLenFeature(shape=[], dtype='string', default_value='')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=8, default_value=None).\n",
      "DEBUG:tensorflow:Transforming feature_column IdentityCategoricalColumn(key='categorical_variable', number_buckets=6, default_value=5).\n",
      "INFO:tensorflow:Assets written to: ../models/pointwise_ranking_demo/final/tfrecord/assets\n",
      "INFO:root:Final model saved to : ../models/pointwise_ranking_demo/final\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = '../models/pointwise_ranking_demo'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    \n",
    "relevance_model.save(\n",
    "    models_dir=MODEL_DIR,\n",
    "    preprocessing_keys_to_fns=preprocessing_fns,\n",
    "    required_fields_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the model for some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully loaded SavedModel from ../models/pointwise_ranking_demo/final/default/\n",
      "WARNING:root:Retraining is not yet supported. Model is loaded with compile=False\n",
      "INFO:root:Is Keras model? True\n",
      "INFO:root:Is compiled? False\n",
      "INFO:root:Finished predicting scores for 25 batches\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>clicked</th>\n",
       "      <th>rank</th>\n",
       "      <th>name_match</th>\n",
       "      <th>query_text</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>b'query_33'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'7q25sku5v3p'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.241376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'query_1169'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'8ax4xxueu16y4f'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.118371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>b'query_414'</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'psidbm0kriq'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.120141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>b'query_503'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'n3wgq7onrw0htvn'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.367418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>b'query_14'</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ywyzthjm9161'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.469881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>b'query_748'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'ckpcj8hcap'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.211330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>b'query_990'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'a5hd4zr'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.229986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>b'query_1385'</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'boyip2'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.189585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>b'query_651'</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'kdkodjukt5581'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>b'query_500'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'8fte46sk'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.255781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>b'query_22'</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'pjxnjalrfp9ed9'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.154823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>b'query_269'</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'j7x5cggqyb'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.172662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>b'query_672'</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'6l6nmod'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.256525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>b'query_728'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'w53xsugzll32k'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.265252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'query_220'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'7bziez2akgqr'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.362416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>b'query_1036'</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0xi5gl'</td>\n",
       "      <td>b'domain_1'</td>\n",
       "      <td>0.145797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b'query_968'</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'jgbkwsga0ejmp'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.126094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>b'query_452'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'b0cwixhhk'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.289586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>b'query_309'</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'l192bbb'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.125161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>b'query_1128'</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'z1w7c7ug3krvk8'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.200681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>b'query_180'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'k91ynibudw0nqek'</td>\n",
       "      <td>b'domain_0'</td>\n",
       "      <td>0.505379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>b'query_1257'</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'3xu2meegyf3o0'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.365419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b'query_1478'</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'pzor8yfeavmfy6p'</td>\n",
       "      <td>b'domain_3'</td>\n",
       "      <td>0.151275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>b'query_1254'</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'cspft9'</td>\n",
       "      <td>b'domain_4'</td>\n",
       "      <td>0.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>b'query_1267'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'spcsx'</td>\n",
       "      <td>b'domain_2'</td>\n",
       "      <td>0.144867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          query_id  clicked  rank  name_match          query_text  \\\n",
       "53     b'query_33'        0     3         1.0      b'7q25sku5v3p'   \n",
       "1    b'query_1169'        0     3         1.0   b'8ax4xxueu16y4f'   \n",
       "118   b'query_414'        0     2         0.0      b'psidbm0kriq'   \n",
       "97    b'query_503'        0     3         0.0  b'n3wgq7onrw0htvn'   \n",
       "30     b'query_14'        1     2         0.0     b'ywyzthjm9161'   \n",
       "65    b'query_748'        1     1         1.0       b'ckpcj8hcap'   \n",
       "65    b'query_990'        0     1         0.0          b'a5hd4zr'   \n",
       "40   b'query_1385'        0     4         0.0           b'boyip2'   \n",
       "49    b'query_651'        0     4         0.0    b'kdkodjukt5581'   \n",
       "117   b'query_500'        0     3         1.0         b'8fte46sk'   \n",
       "71     b'query_22'        0     4         1.0   b'pjxnjalrfp9ed9'   \n",
       "36    b'query_269'        0     2         0.0       b'j7x5cggqyb'   \n",
       "100   b'query_672'        1     3         0.0          b'6l6nmod'   \n",
       "38    b'query_728'        0     5         0.0    b'w53xsugzll32k'   \n",
       "3     b'query_220'        1     1         0.0     b'7bziez2akgqr'   \n",
       "122  b'query_1036'        1     3         0.0           b'0xi5gl'   \n",
       "10    b'query_968'        0     3         1.0    b'jgbkwsga0ejmp'   \n",
       "80    b'query_452'        0     5         1.0        b'b0cwixhhk'   \n",
       "111   b'query_309'        0     2         1.0          b'l192bbb'   \n",
       "50   b'query_1128'        0     4         0.0   b'z1w7c7ug3krvk8'   \n",
       "47    b'query_180'        0     1         1.0  b'k91ynibudw0nqek'   \n",
       "91   b'query_1257'        1     2         0.0    b'3xu2meegyf3o0'   \n",
       "23   b'query_1478'        0    14         0.0  b'pzor8yfeavmfy6p'   \n",
       "82   b'query_1254'        0     5         0.0           b'cspft9'   \n",
       "112  b'query_1267'        0     1         1.0            b'spcsx'   \n",
       "\n",
       "     domain_name  relevance_score  \n",
       "53   b'domain_3'         0.241376  \n",
       "1    b'domain_4'         0.118371  \n",
       "118  b'domain_4'         0.120141  \n",
       "97   b'domain_3'         0.367418  \n",
       "30   b'domain_4'         0.469881  \n",
       "65   b'domain_3'         0.211330  \n",
       "65   b'domain_0'         0.229986  \n",
       "40   b'domain_0'         0.189585  \n",
       "49   b'domain_1'         0.336400  \n",
       "117  b'domain_0'         0.255781  \n",
       "71   b'domain_2'         0.154823  \n",
       "36   b'domain_4'         0.172662  \n",
       "100  b'domain_2'         0.256525  \n",
       "38   b'domain_3'         0.265252  \n",
       "3    b'domain_0'         0.362416  \n",
       "122  b'domain_1'         0.145797  \n",
       "10   b'domain_3'         0.126094  \n",
       "80   b'domain_2'         0.289586  \n",
       "111  b'domain_4'         0.125161  \n",
       "50   b'domain_3'         0.200681  \n",
       "47   b'domain_0'         0.505379  \n",
       "91   b'domain_2'         0.365419  \n",
       "23   b'domain_3'         0.151275  \n",
       "82   b'domain_4'         0.114286  \n",
       "112  b'domain_2'         0.144867  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4ir.base.config.keys import TFRecordTypeKey\n",
    "\n",
    "relevance_model = RelevanceModel(\n",
    "    feature_config=feature_config,\n",
    "    tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "    model_file=os.path.join(MODEL_DIR, 'final/default/'),\n",
    "    logger=logger,\n",
    "    output_name=\"relevance_score\",\n",
    "    file_io=file_io\n",
    ")\n",
    "\n",
    "logger.info(\"Is Keras model? {}\".format(isinstance(relevance_model.model, tf.keras.Model)))\n",
    "logger.info(\"Is compiled? {}\".format(relevance_model.is_compiled))\n",
    "\n",
    "relevance_model.predict(test_dataset=relevance_dataset.test).sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how the TFRecord serving signature works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Example proto: \n",
      "b'\\n\\xf7\\x01\\n\\x16\\n\\nname_match\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80?\\n\\x1c\\n\\x10page_views_score\\x12\\x08\\x12\\x06\\n\\x04]\\x04G>\\n\\x19\\n\\rquality_score\\x12\\x08\\x12\\x06\\n\\x04\\x9b \\x9a>\\n\\x17\\n\\x08query_id\\x12\\x0b\\n\\t\\n\\x07query_1\\n\\r\\n\\x04rank\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x1b\\n\\x0bdomain_name\\x12\\x0c\\n\\n\\n\\x08domain_1\\n\\x1b\\n\\nquery_text\\x12\\r\\n\\x0b\\n\\tLVA3934GV\\n\\x10\\n\\x07clicked\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x1c\\n\\x10text_match_score\\x12\\x08\\x12\\x06\\n\\x044\\xb4\\x19?\\n\\x12\\n\\tdomain_id\\x12\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      "INFO:root:\n",
      "\n",
      "\n",
      "Predictions:\n",
      "INFO:root:{'relevance_score': <tf.Tensor: id=495365, shape=(10, 1), dtype=float32, numpy=\n",
      "array([[0.3996394 ],\n",
      "       [0.47063088],\n",
      "       [0.2115606 ],\n",
      "       [0.36606213],\n",
      "       [0.3594833 ],\n",
      "       [0.20076689],\n",
      "       [0.36606213],\n",
      "       [0.38118273],\n",
      "       [0.37840503],\n",
      "       [0.46712384]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models as kmodels\n",
    "from tensorflow import data\n",
    "\n",
    "model = kmodels.load_model(\n",
    "    os.path.join(MODEL_DIR, 'final/tfrecord/'),\n",
    "    compile=False)\n",
    "infer_fn = model.signatures[\"serving_tfrecord\"]\n",
    "\n",
    "dataset = data.TFRecordDataset(\n",
    "    glob.glob(os.path.join(CSV_DATA_DIR, \"tfrecord\", \"test\", \"*.tfrecord\")))\n",
    "protos = next(iter(dataset.batch(10)))\n",
    "\n",
    "logger.info(\"Example proto: \\n{}\".format(protos[0]))\n",
    "\n",
    "logger.info(\"\\n\\n\\nPredictions:\")\n",
    "logger.info(infer_fn(protos=protos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why you should onboard your ML application to ml4ir today!\n",
    "\n",
    "* Consistent code structure and modularization across projects\n",
    "* Scalable TFRecord data pipeline\n",
    "    * Every ML application shouldn’t have to reinvent the wheel especially when there is barely any documentation on this.\n",
    "    * Consistent file I/O overall\n",
    "* Consistent library versions across projects\n",
    "    * Easily update versions and validate inference time impact, etc\n",
    "* Common Flowsnake enablement\n",
    "    * We can define _git.soma/MLConfigs_ to track and automatically build docker images through strata from ml4ir.\n",
    "* Unified python ↔ JVM interoperability\n",
    "    * Define integration tests\n",
    "    * Allows us to build generic protobuf creation at runtime\n",
    "* Common training abstraction\n",
    "    * Callbacks : checkpointing, early stopping, tensorboard, etc\n",
    "    * Consistent way to save models\n",
    "        * allows us to have generic deployment code\n",
    "* Shared metrics, losses, layers, etc.\n",
    "* Shared feature processing and feature layers across ML models\n",
    "    * long term: shared NLP toolkit, probability toolkit\n",
    "    * short term: categorical, text embeddings\n",
    "* Build models that can be trained with tight coupling:\n",
    "    * transfer learning\n",
    "    * shared embedding layers\n",
    "    * multi task models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### This is just the `end of the beginning` and we would love to take new passengers on this journey!\n",
    "\n",
    "![thanks](images/thats_all_folks.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "\n",
    "                                                            .\n",
    "\n",
    "<center>Psst... You can file github issues -> <a href=\"https://github.com/salesforce/ml4ir/issues\">HERE!</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shhh](images/chris_evans_shush.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
