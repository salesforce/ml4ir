{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's define the feature configuration for our data\n",
    "\n",
    "### ... brace yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Logger is initialized...\n",
      "INFO:root:Reading feature config from YAML string\n",
      "INFO:root:Feature config loaded successfully\n",
      "INFO:root:Trainable Features : \n",
      "feat_0\n",
      "feat_1\n",
      "feat_2\n",
      "query_str\n",
      "group\n",
      "INFO:root:Label : label\n",
      "INFO:root:Metadata Features : \n",
      "query_key\n",
      "label\n",
      "pos\n",
      "INFO:root:[\n",
      "    {\n",
      "        \"name\": \"query_key\",\n",
      "        \"node_name\": \"query_key\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"required\": false,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"label\",\n",
      "        \"node_name\": \"label\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"required\": false,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"feat_0\",\n",
      "        \"node_name\": \"feat_0\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"float\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0.0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"feat_1\",\n",
      "        \"node_name\": \"feat_1\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"float\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0.0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"feat_2\",\n",
      "        \"node_name\": \"feat_2\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"float\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0.0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"query_str\",\n",
      "        \"node_name\": \"query_str\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"string\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null,\n",
      "            \"fn\": \"get_sequence_encoding\",\n",
      "            \"args\": {\n",
      "                \"encoding_type\": \"bilstm\",\n",
      "                \"encoding_size\": 128,\n",
      "                \"embedding_size\": 128,\n",
      "                \"max_length\": 20\n",
      "            }\n",
      "        },\n",
      "        \"preprocessing_info\": [\n",
      "            {\n",
      "                \"fn\": \"preprocess_text\",\n",
      "                \"args\": {\n",
      "                    \"remove_punctuation\": true,\n",
      "                    \"to_lower\": true\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"fn\": \"strip_numbers\"\n",
      "            }\n",
      "        ],\n",
      "        \"serving_info\": {\n",
      "            \"required\": true,\n",
      "            \"default_value\": \"\"\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"group\",\n",
      "        \"node_name\": \"group\",\n",
      "        \"trainable\": true,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": false,\n",
      "        \"is_group_metric_key\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null,\n",
      "            \"fn\": \"custom_categorical_embedding\",\n",
      "            \"args\": {\n",
      "                \"vocabulary_size\": 16,\n",
      "                \"embedding_size\": 128\n",
      "            }\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"required\": false,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"context\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"pos\",\n",
      "        \"node_name\": \"pos\",\n",
      "        \"trainable\": false,\n",
      "        \"dtype\": \"int64\",\n",
      "        \"log_at_inference\": true,\n",
      "        \"feature_layer_info\": {\n",
      "            \"type\": \"numeric\",\n",
      "            \"shape\": null\n",
      "        },\n",
      "        \"serving_info\": {\n",
      "            \"required\": true,\n",
      "            \"default_value\": 0\n",
      "        },\n",
      "        \"tfrecord_type\": \"sequence\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Set up the feature configurations\n",
    "from ml4ir.features.feature_config import parse_config\n",
    "from ml4ir.features.feature_config import ExampleFeatureConfig\n",
    "from ml4ir.config.keys import TFRecordTypeKey\n",
    "import json\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"Logger is initialized...\")\n",
    "\n",
    "feature_config_yaml = '''\n",
    "query_key: \n",
    "  name: query_key\n",
    "  node_name: query_key\n",
    "  trainable: false\n",
    "  dtype: int64\n",
    "  log_at_inference: true\n",
    "  feature_layer_info:\n",
    "    type: numeric\n",
    "    shape: null\n",
    "  serving_info:\n",
    "    required: false\n",
    "    default_value: 0\n",
    "  tfrecord_type: context\n",
    "label:\n",
    "  name: label\n",
    "  node_name: label\n",
    "  trainable: false\n",
    "  dtype: int64\n",
    "  log_at_inference: true\n",
    "  feature_layer_info:\n",
    "    type: numeric\n",
    "    shape: null\n",
    "  serving_info:\n",
    "    required: false\n",
    "    default_value: 0\n",
    "  tfrecord_type: sequence\n",
    "features:\n",
    "  - name: feat_0\n",
    "    node_name: feat_0\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: feat_1\n",
    "    node_name: feat_1\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: feat_2\n",
    "    node_name: feat_2\n",
    "    trainable: true\n",
    "    dtype: float\n",
    "    log_at_inference: false\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      required: true\n",
    "      default_value: 0.0\n",
    "    tfrecord_type: sequence\n",
    "  - name: query_str\n",
    "    node_name: query_str\n",
    "    trainable: true\n",
    "    dtype: string\n",
    "    log_at_inference: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      fn: get_sequence_encoding\n",
    "      args:\n",
    "        encoding_type: bilstm\n",
    "        encoding_size: 128\n",
    "        embedding_size: 128\n",
    "        max_length: 20\n",
    "    preprocessing_info:\n",
    "      - fn: preprocess_text\n",
    "        args:\n",
    "          remove_punctuation: true\n",
    "          to_lower: true\n",
    "      - fn: strip_numbers\n",
    "    serving_info:\n",
    "      required: true\n",
    "      default_value: \"\"\n",
    "    tfrecord_type: context\n",
    "  - name: group\n",
    "    node_name: group\n",
    "    trainable: true\n",
    "    dtype: int64\n",
    "    log_at_inference: false\n",
    "    is_group_metric_key: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "      fn: custom_categorical_embedding\n",
    "      args:\n",
    "        vocabulary_size: 16\n",
    "        embedding_size: 128\n",
    "    serving_info:\n",
    "      required: false\n",
    "      default_value: 0\n",
    "    tfrecord_type: context\n",
    "  - name: pos\n",
    "    node_name: pos\n",
    "    trainable: false\n",
    "    dtype: int64\n",
    "    log_at_inference: true\n",
    "    feature_layer_info:\n",
    "      type: numeric\n",
    "      shape: null\n",
    "    serving_info:\n",
    "      required: true\n",
    "      default_value: 0\n",
    "    tfrecord_type: sequence\n",
    "'''\n",
    "feature_config: ExampleFeatureConfig = parse_config(TFRecordTypeKey.EXAMPLE, feature_config_yaml, logger=logger)\n",
    "    \n",
    "logging.info(json.dumps(feature_config.get_all_features(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to load the data and save awesome TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_key</th>\n",
       "      <th>query_str</th>\n",
       "      <th>pos</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>MHS7A7RJB1Y4BJT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MHS7A7RJB1Y4BJT</td>\n",
       "      <td>1</td>\n",
       "      <td>1.063190</td>\n",
       "      <td>0.205381</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>6</td>\n",
       "      <td>1.368108</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>3</td>\n",
       "      <td>1.370628</td>\n",
       "      <td>0.041261</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>KNJNWV</td>\n",
       "      <td>4</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>0.082535</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_key        query_str  pos    feat_0    feat_1   feat_2  label  group\n",
       "0          2  MHS7A7RJB1Y4BJT    2  0.473730  0.000000  0.00000      0      2\n",
       "1          2  MHS7A7RJB1Y4BJT    1  1.063190  0.205381  0.30103      1      2\n",
       "2          5           KNJNWV    6  1.368108  0.030636  0.00000      0      0\n",
       "3          5           KNJNWV    3  1.370628  0.041261  0.30103      0      0\n",
       "4          5           KNJNWV    4  1.366700  0.082535  0.30103      0      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml4ir.io import file_io\n",
    "from ml4ir.data import tfrecord_writer\n",
    "import glob\n",
    "\n",
    "# Load data\n",
    "df = file_io.read_df_list(glob.glob('/Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv/train/file_0.csv'))\n",
    "\n",
    "# Save as TFRecord SequenceExample/Example\n",
    "tfrecord_writer.write_from_df(df,\n",
    "                              tfrecord_file='/Users/ashish.srinivasa/search_relevance/data/demo/tfrecords/file_0.tfrecord',\n",
    "                              feature_config=feature_config,\n",
    "                              tfrecord_type=TFRecordTypeKey.EXAMPLE)\n",
    "\n",
    "# Let's see what it looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TFRecords and add custom preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_key': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'label': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'feat_0': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_1': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_2': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_str': FixedLenFeature(shape=[], dtype='string', default_value=''), 'group': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'pos': FixedLenFeature(shape=[], dtype='int64', default_value=0)}\n",
      "({'feat_0': [[0.473729521]\n",
      " [1.06319]\n",
      " [1.36810815]\n",
      " [1.37062836]\n",
      " [1.36669993]],\n",
      "  'feat_1': [[0]\n",
      " [0.205380633]\n",
      " [0.0306360275]\n",
      " [0.0412614979]\n",
      " [0.0825348869]],\n",
      "  'feat_2': [[0]\n",
      " [0.30103]\n",
      " [0]\n",
      " [0.30103]\n",
      " [0.30103]],\n",
      "  'group': [[2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]],\n",
      "  'pos': [[2]\n",
      " [1]\n",
      " [6]\n",
      " [3]\n",
      " [4]],\n",
      "  'query_key': [[2]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]],\n",
      "  'query_str': [[\"mhsarjbybjt\"]\n",
      " [\"mhsarjbybjt\"]\n",
      " [\"knjnwv\"]\n",
      " [\"knjnwv\"]\n",
      " [\"knjnwv\"]]},\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]])\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.data import tfrecord_reader\n",
    "from tensorflow import print as tfprint\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def strip_numbers(feature_tensor):\n",
    "    return tf.strings.regex_replace(feature_tensor, \"[0-9]\", \"\")\n",
    "\n",
    "# Define per instance preprocessing functions\n",
    "preprocessing_fns = {\n",
    "    \"strip_numbers\": strip_numbers\n",
    "}\n",
    "\n",
    "# Create a TFRecord dataset\n",
    "dataset = tfrecord_reader.read(data_dir='/Users/ashish.srinivasa/search_relevance/data/demo/tfrecords/',\n",
    "                               feature_config=feature_config,\n",
    "                               tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "                               preprocessing_keys_to_fns=preprocessing_fns)\n",
    "\n",
    "tfprint(next(iter(dataset.batch(5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map, Filter, Filter, Batch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variety of map, reduce, filter, shuffle operations can be used here\n",
    "# dataset = dataset.<map, filter, reduce>(tf_preprocess_fn)\n",
    "\n",
    "# NOTE: This is lazy batching\n",
    "dataset = dataset.batch(batch_size=128, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or... you can do all of that for train, val and test in _one_ step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading 1 files from [/Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv/train/file_0.csv, ..\n",
      "INFO:root:Writing SequenceExample protobufs to : /Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv/tfrecord/train/file_0.tfrecord\n",
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['/Users/ashish.srinivasa/search_relevance/ml4ir/p\n",
      "INFO:root:Reading 1 files from [/Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv/validation/file_0.csv, ..\n",
      "INFO:root:Writing SequenceExample protobufs to : /Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv/tfrecord/validation/file_0.tfrecord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_key': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'label': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'feat_0': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_1': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_2': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_str': FixedLenFeature(shape=[], dtype='string', default_value=''), 'group': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'pos': FixedLenFeature(shape=[], dtype='int64', default_value=0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['/Users/ashish.srinivasa/search_relevance/ml4ir/p\n",
      "INFO:root:Reading 1 files from [/Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv/test/file_0.csv, ..\n",
      "INFO:root:Writing SequenceExample protobufs to : /Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv/tfrecord/test/file_0.tfrecord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_key': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'label': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'feat_0': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_1': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_2': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_str': FixedLenFeature(shape=[], dtype='string', default_value=''), 'group': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'pos': FixedLenFeature(shape=[], dtype='int64', default_value=0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Created TFRecordDataset from SequenceExample protobufs from 1 files : ['/Users/ashish.srinivasa/search_relevance/ml4ir/p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_key': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'label': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'feat_0': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_1': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_2': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_str': FixedLenFeature(shape=[], dtype='string', default_value=''), 'group': FixedLenFeature(shape=[], dtype='int64', default_value=0), 'pos': FixedLenFeature(shape=[], dtype='int64', default_value=0)}\n",
      "<BatchDataset shapes: ({query_key: (128, 1), feat_0: (128, 1), feat_1: (128, 1), feat_2: (128, 1), query_str: (128, 1), group: (128, 1), pos: (128, 1)}, (128, 1)), types: ({query_key: tf.int64, feat_0: tf.float32, feat_1: tf.float32, feat_2: tf.float32, query_str: tf.string, group: tf.int64, pos: tf.int64}, tf.int64)>\n",
      "<BatchDataset shapes: ({query_key: (128, 1), feat_0: (128, 1), feat_1: (128, 1), feat_2: (128, 1), query_str: (128, 1), group: (128, 1), pos: (128, 1)}, (128, 1)), types: ({query_key: tf.int64, feat_0: tf.float32, feat_1: tf.float32, feat_2: tf.float32, query_str: tf.string, group: tf.int64, pos: tf.int64}, tf.int64)>\n",
      "<BatchDataset shapes: ({query_key: (128, 1), feat_0: (128, 1), feat_1: (128, 1), feat_2: (128, 1), query_str: (128, 1), group: (128, 1), pos: (128, 1)}, (128, 1)), types: ({query_key: tf.int64, feat_0: tf.float32, feat_1: tf.float32, feat_2: tf.float32, query_str: tf.string, group: tf.int64, pos: tf.int64}, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.data.relevance_dataset import RelevanceDataset\n",
    "from ml4ir.config.keys import DataFormatKey\n",
    "\n",
    "relevance_dataset = RelevanceDataset(\n",
    "        data_dir='/Users/ashish.srinivasa/search_relevance/ml4ir/python/applications/ranking/tests/data/csv',\n",
    "        data_format=DataFormatKey.CSV,\n",
    "        feature_config=feature_config,\n",
    "        tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "        batch_size=128,\n",
    "        preprocessing_keys_to_fns=preprocessing_fns,\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "tfprint(relevance_dataset.train)\n",
    "tfprint(relevance_dataset.validation)\n",
    "tfprint(relevance_dataset.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define a model, already!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : insert architecture diagram\n",
    "#\n",
    "# RelevanceModel(\n",
    "#     Scorer(\n",
    "#         InteractionModel(\n",
    "#             Inputs\n",
    "#         ),\n",
    "#         Loss),\n",
    "#     Metrics,\n",
    "#     Optimizer,\n",
    "#     Callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Define the Interaction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4ir.model.scoring.interaction_model import InteractionModel, UnivariateInteractionModel\n",
    "from ml4ir.config.keys import TFRecordTypeKey\n",
    "\n",
    "# Define custom feature layer ops\n",
    "def get_categorical_embedding(input_feature, feature_info):\n",
    "    \"\"\"Embedding lookup for categorical features\"\"\"\n",
    "    \n",
    "    feature_layer_info = feature_info.get(\"feature_layer_info\")\n",
    "    return layers.Embedding(input_dim=feature_layer_info[\"args\"][\"vocabulary_size\"],\n",
    "                     output_dim=feature_layer_info[\"args\"][\"embedding_size\"],\n",
    "                     name=\"categorical_embedding_{}\".format(feature_info.get(\"name\")),\n",
    "                 )(input_feature)\n",
    "\n",
    "feature_layer_fns = {\n",
    "    \"custom_categorical_embedding\": get_categorical_embedding\n",
    "}\n",
    "\n",
    "interaction_model: InteractionModel = UnivariateInteractionModel(\n",
    "                                            feature_config=feature_config,\n",
    "                                            feature_layer_keys_to_fns=feature_layer_fns,\n",
    "                                            tfrecord_type=TFRecordTypeKey.EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{\n",
      "    \"architecture_key\": \"dnn\",\n",
      "    \"layers\": [\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"first_dense\",\n",
      "            \"units\": 256,\n",
      "            \"activation\": \"relu\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dropout\",\n",
      "            \"name\": \"first_dropout\",\n",
      "            \"rate\": 0.0\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"second_dense\",\n",
      "            \"units\": 64,\n",
      "            \"activation\": \"relu\"\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dropout\",\n",
      "            \"name\": \"second_dropout\",\n",
      "            \"rate\": 0.0\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"dense\",\n",
      "            \"name\": \"final_dense\",\n",
      "            \"units\": 1,\n",
      "            \"activation\": null\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.model.scoring.scoring_model import ScorerBase, RelevanceScorer\n",
    "from ml4ir.model.losses.loss_base import RelevanceLossBase\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "class MyCustomLoss(RelevanceLossBase):\n",
    "    def get_loss_fn(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Define a sigmoid cross entropy loss\n",
    "        Additionally can pass in record positions to handle positional bias\n",
    "\n",
    "        \"\"\"\n",
    "        bce = losses.BinaryCrossentropy(reduction=losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "        mask = kwargs.get(\"mask\")\n",
    "\n",
    "        def _loss_fn(y_true, y_pred):\n",
    "            # NOTE: Can use any of the metadata features to qualify your loss here\n",
    "            return bce(y_true, y_pred)\n",
    "\n",
    "        return _loss_fn\n",
    "\n",
    "    def get_final_activation_op(self, output_name):\n",
    "        return lambda logits, mask: layers.Activation(\"sigmoid\", name=output_name)(logits)\n",
    "\n",
    "scorer: ScorerBase = RelevanceScorer.from_model_config_file(\n",
    "    model_config_file='/Users/ashish.srinivasa/search_relevance/ml4ir/python/ml4ir/config/default_model_config.yaml',\n",
    "    interaction_model=interaction_model,\n",
    "    loss=MyCustomLoss(),\n",
    "    output_name=\"relevance_score\")\n",
    "    \n",
    "logger.info(json.dumps(scorer.model_config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics as kmetrics\n",
    "\n",
    "metrics = ['binary_accuracy', kmetrics.Precision(name='precision')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Optimizer\n",
    "from ml4ir.model.optimizer import get_optimizer\n",
    "from ml4ir.config.keys import OptimizerKey\n",
    "\n",
    "optimizer: Optimizer = get_optimizer(\n",
    "                optimizer_key=OptimizerKey.ADAM,\n",
    "                learning_rate=0.01,\n",
    "                learning_rate_decay=0.94,\n",
    "                learning_rate_decay_steps=1000,\n",
    "                gradient_clip_value=50,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now... let's put it all together (shhh!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "query_str (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_DecodePaddedRaw (Te [(None, 1, 20)]      0           query_str[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 20)]         0           tf_op_layer_DecodePaddedRaw[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 128)      32768       tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "feat_0 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "feat_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "feat_2 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128)          98816       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "group (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 1)]       0           feat_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 1, 1)]       0           feat_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 1, 1)]       0           feat_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 1, 128)]     0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "categorical_embedding_group (Em (None, 1, 128)       2048        group[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_train_features (Ten [(None, 1, 259)]     0           tf_op_layer_ExpandDims_1[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_2[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_3[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "                                                                 categorical_embedding_group[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "first_dense (Dense)             (None, 1, 256)       66560       tf_op_layer_train_features[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "first_dropout (Dropout)         (None, 1, 256)       0           first_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "second_dense (Dense)            (None, 1, 64)        16448       first_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "second_dropout (Dropout)        (None, 1, 64)        0           second_dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dense (Dense)             (None, 1, 1)         65          second_dropout[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 1)]          0           final_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pos (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "query_key (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "relevance_score (Activation)    (None, 1)            0           tf_op_layer_Squeeze[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 216,705\n",
      "Trainable params: 216,705\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from ml4ir.model.relevance_model import RelevanceModel\n",
    "from ml4ir.config.keys import OptimizerKey\n",
    "\n",
    "relevance_model = RelevanceModel(\n",
    "        feature_config=feature_config,\n",
    "        scorer=scorer,\n",
    "        metrics=metrics,\n",
    "        optimizer=optimizer,\n",
    "        tfrecord_type=TFRecordTypeKey.EXAMPLE,\n",
    "        output_name=\"relevance_score\",\n",
    "        logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training Model\n",
      "INFO:root:Starting Epoch : 1\n",
      "INFO:root:{}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 1 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.6951301, 'binary_accuracy': 0.4296875, 'precision': 0.2795699}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 3s 3s/step - loss: 0.6951 - binary_accuracy: 0.4297 - precision: 0.2796WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.165522). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.165522). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25/Unknown - 5s 187ms/step - loss: 0.5846 - binary_accuracy: 0.7237 - precision: 0.2796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 1 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.5673238, 'binary_accuracy': 0.72415864, 'precision': 0.2795699}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     44/Unknown - 6s 131ms/step - loss: 0.5744 - binary_accuracy: 0.7282 - precision: 0.2796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.73899, saving model to /Users/ashish.srinivasa/search_relevance/model_training/test/models/checkpoint.tf\n",
      "WARNING:tensorflow:From /Users/ashish.srinivasa/search_relevance/ml4ir/python/env/.ranking_venv3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ashish.srinivasa/search_relevance/ml4ir/python/env/.ranking_venv3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/ashish.srinivasa/search_relevance/model_training/test/models/checkpoint.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/ashish.srinivasa/search_relevance/model_training/test/models/checkpoint.tf/assets\n",
      "INFO:root:End of Epoch 1\n",
      "INFO:root:{'loss': 0.5744227672165091, 'binary_accuracy': 0.7281605, 'precision': 0.2795699, 'val_loss': 0.5471044494347139, 'val_binary_accuracy': 0.7389915, 'val_precision': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 35s 796ms/step - loss: 0.5744 - binary_accuracy: 0.7282 - precision: 0.2796 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 2\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 2 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.53769475, 'binary_accuracy': 0.75, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5509 - binary_accuracy: 0.7366 - precision: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 2 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.5610144, 'binary_accuracy': 0.7364784, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5515 - binary_accuracy: 0.7353 - precision: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n",
      "INFO:root:End of Epoch 2\n",
      "INFO:root:{'loss': 0.551779412410476, 'binary_accuracy': 0.7354403, 'precision': 0.0, 'val_loss': 0.5538304055278952, 'val_binary_accuracy': 0.7389915, 'val_precision': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.73899\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 4s 93ms/step - loss: 0.5518 - binary_accuracy: 0.7354 - precision: 0.0000e+00 - val_loss: 0.5538 - val_binary_accuracy: 0.7390 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Epoch : 3\n",
      "INFO:root:{}\n",
      "INFO:root:[epoch: 3 | batch: 0] {'batch': 0, 'size': 128, 'loss': 0.5520214, 'binary_accuracy': 0.75, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "25/44 [================>.............] - ETA: 1s - loss: 0.5525 - binary_accuracy: 0.7366 - precision: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[epoch: 3 | batch: 25] {'batch': 25, 'size': 128, 'loss': 0.56047297, 'binary_accuracy': 0.7364784, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.5515 - binary_accuracy: 0.7353 - precision: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Model\n",
      "INFO:root:Completed evaluating model\n",
      "INFO:root:None\n",
      "INFO:root:End of Epoch 3\n",
      "INFO:root:{'loss': 0.5519916056232019, 'binary_accuracy': 0.7354403, 'precision': 0.0, 'val_loss': 0.5560686249624599, 'val_binary_accuracy': 0.7389915, 'val_precision': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.73899\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/44 [==============================] - 4s 97ms/step - loss: 0.5520 - binary_accuracy: 0.7354 - precision: 0.0000e+00 - val_loss: 0.5561 - val_binary_accuracy: 0.7390 - val_precision: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Completed training model\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "relevance_model.fit(relevance_dataset, \n",
    "                    num_epochs=5, \n",
    "                    models_dir='/Users/ashish.srinivasa/search_relevance/model_training/test/models',\n",
    "                    logs_dir='/Users/ashish.srinivasa/search_relevance/model_training/test/logs',\n",
    "                    monitor_metric='val_binary_accuracy',\n",
    "                    monitor_mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's save the model(... and don't forget about serving signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ashish.srinivasa/search_relevance/ml4ir/python/env/.ranking_venv3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ashish.srinivasa/search_relevance/ml4ir/python/env/.ranking_venv3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/ashish.srinivasa/search_relevance/model_training/test/models/final/default/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/ashish.srinivasa/search_relevance/model_training/test/models/final/default/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feat_0': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_1': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'feat_2': FixedLenFeature(shape=[], dtype='float', default_value=0.0), 'query_str': FixedLenFeature(shape=[], dtype='string', default_value=''), 'pos': FixedLenFeature(shape=[], dtype='int64', default_value=0)}\n",
      "INFO:tensorflow:Assets written to: /Users/ashish.srinivasa/search_relevance/model_training/test/models/final/tfrecord/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/ashish.srinivasa/search_relevance/model_training/test/models/final/tfrecord/assets\n",
      "INFO:root:Final model saved to : /Users/ashish.srinivasa/search_relevance/model_training/test/models/final\n"
     ]
    }
   ],
   "source": [
    "relevance_model.save(\n",
    "    models_dir='/Users/ashish.srinivasa/search_relevance/model_training/test/models',\n",
    "    preprocessing_keys_to_fns=preprocessing_fns,\n",
    "    required_fields_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the model for some fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
